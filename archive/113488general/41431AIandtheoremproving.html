---
layout: archive
title: Lean Prover Zulip Chat Archive
permalink: archive/113488general/41431AIandtheoremproving.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/113488general/index.html">general</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html">AI and theorem proving</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">

{% raw %}
<a name="166042079"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042079" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042079">Jason Rute (May 19 2019 at 21:53)</a>:</h4>
<p>First, since I’ve only posted a few times in here, I thought I’d introduce myself.  I’m a former mathematician turned data scientist.  I used to work on computability theory and algorithmic randomness.  Jeremy Avigad was my advisor, which makes me an academic sibling to a couple of you.  Before graduate school, I worked on the Flyspeck project for a bit, but then lost interest in interactive theorem proving.  I’ve become more interested in it again with Lean and with the many advancements in AI and theorem proving.  </p>
<p>I’m especially interested in AI for theorem proving and I closely follow the field (as an outsider). I’m always happy to chat about it.  Since there have been many discussions here on the topic and I’d thought I’d share some resources and thoughts I have.  (Disclaimer: I am only an interested outsider.  I am not involved in any way with this research.)</p>

<a name="166042082"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042082" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042082">Jason Rute (May 19 2019 at 21:53)</a>:</h4>
<p><a href="https://slideslive.com/38909911/no-one-shall-drive-us-from-the-semantic-ai-paradise-of-computerunderstandable-math-and-science" target="_blank" title="https://slideslive.com/38909911/no-one-shall-drive-us-from-the-semantic-ai-paradise-of-computerunderstandable-math-and-science">This talk</a> by Joseph Urban is a great introduction to the state of field.  For more in depth, here are two <a href="http://phdopen.mimuw.edu.pl/index.php?page=z18w2" target="_blank" title="http://phdopen.mimuw.edu.pl/index.php?page=z18w2">sets of</a> <a href="http://cl-informatik.uibk.ac.at/teaching/ss18/mltp/content.php" target="_blank" title="http://cl-informatik.uibk.ac.at/teaching/ss18/mltp/content.php">lectures</a> on the subject by Cezary Kaliszyk.  (The first is just three lectures and has videos.)  Indeed, these two people and their respective labs seem to be leading the charge in AI for theorem proving.</p>
<p>Recently Berkeley, OpenAI, Google AI, and DeepMind are also getting into the field, which is really exciting.  Berkeley and OpenAI released <a href="https://github.com/ml4tp/gamepad" target="_blank" title="https://github.com/ml4tp/gamepad">GamePad</a> which is a learning environment to train AI agents in Coq.  Google AI just released a similar learning environment <a href="https://sites.google.com/view/holist/home" target="_blank" title="https://sites.google.com/view/holist/home">HOList</a> for HOL-Light (see slides at <a href="http://aitp-conference.org/2019/" target="_blank" title="http://aitp-conference.org/2019/">AITP 2019</a>).  Both of these projects provide datasets (e.g. the Flyspeck library) and some weak baselines.  As for DeepMind, Demis Hassabis recently mentioned “theorem proving” as one of the science projects they are working on right now (search “theorem” in <a href="https://cbmm.mit.edu/video/power-self-learning-systems" target="_blank" title="https://cbmm.mit.edu/video/power-self-learning-systems">this video/transcript</a>).</p>
<p>As for tactic-based ITPs, besides GamePad and HOList, there is <a href="https://github.com/HOL-Theorem-Prover/HOL/tree/master/src/tactictoe" target="_blank" title="https://github.com/HOL-Theorem-Prover/HOL/tree/master/src/tactictoe">TacticToe</a>, which is probably the most useful of the tools so far.  It fills in tactic proofs for HOL4 (<a href="https://arxiv.org/abs/1804.00596" target="_blank" title="https://arxiv.org/abs/1804.00596">paper</a>, slides/video at <a href="http://aitp-conference.org/2018/" target="_blank" title="http://aitp-conference.org/2018/">AITP 2018</a>).  Also, there appears to be <a href="https://github.com/data61/PSL" target="_blank" title="https://github.com/data61/PSL">PSL</a> for Isabelle, but I don't know much about it.</p>
<p>In another channel someone asked about using AlphaZero (or AlphaGo Zero) methods for theorem proving.  Despite what most people think, the AlphaZero algorithm isn’t so much about playing games as training an agent to search through a tree.  Historically, tree search algorithms in games used min-max with alpha-beta pruning.  That is they use a depth-first search to a certain level of depth, hand written heuristics, heavy pruning, and other optimizations—very similar to the tree searches methods in ATPs.  In contrast, Monte Carlo Tree Search (MCTS) explores paths through the tree “at random” (formally it uses UCBT and random rollouts) avoiding the need for hand-written heuristics.  The AlphaZero variant of MCTS eliminates the need to explore to the end of the tree, instead using policy and value heuristics learned by a neural network to guide the search towards nodes in the tree that look “valuable”.  Eliminating the need to explore to the end makes AlphaZero MCTS useful in other tree and graph search problems with sparse terminal states, such as theorem proving.  Indeed, most theorem proving settings can be thought of as tree search problems.  The nodes in the tree are partially constructed proofs and edges are manipulations which lead to the new partial proof.  For example, in tactic-based ITPs, the nodes correspond to a sets of open goals and the edges correspond to tactics which can be applied to the goals.  In other settings, the nodes are are partially built proof trees or tableaus and the edges correspond to inference rules (in say a cut-free sequent calculus).  Many papers in AI and theorem proving are starting to experiment with MCTS.  For example, the TacticToe paper (the most recent version) uses MCTS, but with hand-engineered heuristics.</p>
<p>Another important trend in theorem proving is reinforcement learning (RL), that is learning by exploring the space instead of using labeled data.  This is important since as many have stated there isn’t a lot of human labeled data to use in theorem proving.  Recently, there have been some successful experiments in this area: <a href="https://arxiv.org/abs/1805.07563" target="_blank" title="https://arxiv.org/abs/1805.07563">rlCOP</a> (slides/video at <a href="http://aitp-conference.org/2018/" target="_blank" title="http://aitp-conference.org/2018/">AITP 2018</a>), <a href="https://arxiv.org/abs/1807.08058" target="_blank" title="https://arxiv.org/abs/1807.08058">an RL-trained QBF solver</a>, and <a href="https://arxiv.org/abs/1811.00796v1" target="_blank" title="https://arxiv.org/abs/1811.00796v1">an RL-trained intuitionistic theorem prover</a>.  These results are really encouraging and many of these systems use MCTS and other ideas borrowed from AlphaZero.  Nonetheless, the systems are still quite limited.</p>
<p>There are also applications of AI/ML to SMT solvers, SAT solvers, QBF solvers, resolution theorem provers, connection-style theorem provers, and a variety of different logics.  While there aren’t a lot of researchers directly working on theorem proving, there a number of related research topics including program synthesis, question answering and reasoning in natural language, theorem proving in large relational knowledge databases, and neural-symbolic learning.</p>

<a name="166042086"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042086" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042086">Jason Rute (May 19 2019 at 21:54)</a>:</h4>
<p>I’d also like to share some major trends and challenges I’ve seen in the area of AI for theorem proving.  </p>
<p>Suppose an agent wants to prove a theorem or fill in a gap in a proof.  It could prove it from scratch, but it is much easier to use previously proved facts.  However, if we have a long list of previously proved facts, our combinatorial search space will grow considerably.  This is called the “premise selection problem”.  (For some tactics one also has to specify terms as arguments.  This again is a sort of premise selection problem.)</p>
<p>More powerfully, one would like an agent which creates its own definitions and lemmas.  (This is akin to the difference between a proof system with and without cut, the former allowing arbitrary lemmas.)  All the current benchmarks I am aware of use theorem proving libraries where the intermediate lemmas are already given (or can be chosen from a large list of previously proved results).  I know of no system which has the ability to make its own definitions or lemmas.  (Although in the related field of program synthesis there is work on automatic creation of reusable subroutines.)</p>
<p>Another major trend is feature extraction.  In order to do machine learning on formulas, one has to extract the useful information from the formula.  One time honored tradition is manual “feature engineering”.  While neural networks are really good at automatically discovering features, many of the most successful current systems (e.g. TacticToe) still don’t use neural networks since they are too slow.  Instead they use hand-engineered features in conjunction with faster machine learning methods like boosted trees or nearest-neighbor search.  Nonetheless, I think in the end neural networks will win.  It is already established that neural networks allow one to significantly decrease the search space in many theorem proving tasks, and as we build systems that are more ambitious this exponential speedup in search space will outpace the linear slowdown in feature computation.  While tools like SMT solvers are massively optimized, they only work well in narrow domains.  For research math problems, we need an agent which can learn from the cutting edge without hand engineering.  And we would be willing to wait an hour to solve a problem that would take a week or more for a human to solve.</p>
<p>Even if one uses neural networks to extract features from terms (or formulas, goals, etc.), there are a number of design choices.  While terms (and formulas, etc.) are just strings of symbols, neural networks which are designed for strings of symbols (1D CNNs and LSTMs) don’t seem to work as well.  The reason is that that terms have a deep recursive tree-based structure.  There has been more success with recursive tree neural networks which better capture this recursive structure.  However, formulas aren’t really well represented as trees either because they have bound variables with arbitrary names.  Instead, it seems to be best to use DeBruijn representations where each bound variable is connected to the associated quantifier.  Graph neural networks are amenable to this representation of a term (or formula, etc) as a graph, and seem to do empirically better.  However graph neural networks are still a new concept and more experimentation is likely needed.</p>
<p>Despite all the areas for improvement, I am very hopeful.  I have no doubt that theorem proving is difficult, but incremental progress can have tangible value: Speeding up SMT and SAT solvers.  Learning to quickly prove basic facts in new domains.  Improving the tactics in ITPs to fill in the “obvious parts”.  Improving hardware and software formalization.  Speeding up compilers (even the Lean compiler/type-checker).  This will likely come before automatically proving Math Olympiad problems, auto-formalizing arXiv, having a computer develop new areas of mathematics, or solving really hard research problems.</p>
<p>Another reason to be hopeful is that the tools being built in AI are amazingly general.  For example, two of the important tools used in AlphaStar (DeepMind’s recent Starcraft II AI) are transformers and LSTMs.  Both of these were developed for sequence-to-sequence learning such as machine translation.  Nonetheless, they also turned out to be very applicable to playing real-time strategy games and a host of other problems such as creating computer generated images.  This reusability of tools is a big win.  Researchers don’t need to be working on theorem proving in particular to develop ideas, such as MCTS and graph neural networks, which can be repurposed for theorem proving.  Indeed the problems plaguing AI and theorem proving, such as an infinite search space, are also problems in many other areas of AI.  (Just search for “the bigger picture” in <a href="https://cbmm.mit.edu/video/power-self-learning-systems" target="_blank" title="https://cbmm.mit.edu/video/power-self-learning-systems">this DeepMind talk</a>).  Moreover, I think many of the advanced ideas in AI haven’t even been tried in theorem proving (neither the HOList nor GamePad baselines use graph neural networks for example), which is why I am very excited that the big players (e.g. DeepMind) are joining the field since they have a lot of experience and have shown a willingness to tackle ambitious projects.  Now we just need to convince them that this is worth the payoff!</p>
<p>And finally it seems that, by using reinforcement learning and lots of computer power, we can quickly scale up from ok progress on an AI task to great progress.  Thinking big (maybe too big), if we can teach an AI agent how to make definitions and lemmas, how to use curiosity to explore a new mathematical subject, and how to effectively leverage previous proved knowledge to build new knowledge, then we might—just might—get really impressive results…</p>

<a name="166042146"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042146" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042146">Jason Rute (May 19 2019 at 21:55)</a>:</h4>
<p>(Sorry for the long posts.  As Jeremy can attest to, I haven't learned the skill of short writing.)</p>

<a name="166042194"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042194" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042194">Jason Rute (May 19 2019 at 21:56)</a>:</h4>
<p>(Also, I know many of these resources have been shared many times.  I thought there was value in putting them together in the same place.)</p>

<a name="166042216"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042216" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042216">Kevin Buzzard (May 19 2019 at 21:57)</a>:</h4>
<p>Thanks a lot for these -- I find myself a few times a week on an exercise machine and it's great to have stuff to watch there -- I still haven't figured out how to do Lean whilst pedalling energetically.</p>

<a name="166042393"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042393" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042393">Kevin Buzzard (May 19 2019 at 22:01)</a>:</h4>
<p>Making mathematical definitions is an art -- it's analogous to making new tools. Getting computers to prove theorems using a given set of tools sounds like a much easier problem, and even that seems very difficult to do at the minute.</p>

<a name="166042445"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042445" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042445">Kevin Buzzard (May 19 2019 at 22:02)</a>:</h4>
<p>Brian Conrad is fond of challenging me to get my computer to invent / discover a proof that there are infinitely many primes, and even given the fact that the integers are a unique factorization domain I think a computer would find this hard to do.</p>

<a name="166042891"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166042891" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166042891">Jason Rute (May 19 2019 at 22:15)</a>:</h4>
<p>I agree discovering definitions and "interesting" results will be one of the last things we figure out how to do well.  As far as making new tools, I think to scale automatic theorem proving, we will have to figure out how to build new tactics or make simple lemmas that factor out common proof steps.  This is related to other problems in AI such as hierarchical reinforcement learning where one wants to learn new high level actions made up of low level actions.  Theorem proving is interesting in that the ability to package small steps into one big step is built into the theorem proving framework already, but it is not clear how one would take advantage of it.</p>

<a name="166043229"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166043229" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166043229">Jason Rute (May 19 2019 at 22:24)</a>:</h4>
<p>But speaking of hierarchical RL, the <a href="https://openai.com/blog/openai-five/" target="_blank" title="https://openai.com/blog/openai-five/">OpenAI Five</a> Dota AI is an interesting example.  They thought they would have to solve hierarchical reinforcement learning before they could solve Dota, but it turns out the existing tools (namely LSTMs) already were capable of learning complicated strategies which are executed over a very long time period.  So maybe lemmas and hierarchical RL is not as important as I think.</p>

<a name="166043629"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166043629" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166043629">Moses Schönfinkel (May 19 2019 at 22:36)</a>:</h4>
<p>And yet it didn't even learn the neutral-camp pull into lane! ;) Thanks for the write-up.</p>

<a name="166045274"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166045274" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166045274">Jesse Michael Han (May 19 2019 at 23:21)</a>:</h4>
<p>This is a nice summary. It would be nice to compare the rlCoP-style approach of guiding tableaux/superposition calculus proof search with the <code>tidy_on_steroids</code> approach of TacticToe/HOList, but it doesn't seem like they've been implemented for the same systems yet.</p>

<a name="166056603"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166056603" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166056603">Jason Rute (May 20 2019 at 04:54)</a>:</h4>
<p>The short answer to your question is that the main ideas of the systems are similar.  Connection tableau or tactic-goals, it is basically the same idea.  We progressively modify the proof goal until it is solved.  The devil is in the details.  These details include generating human data by recording proofs and hooking up the theorem prover to a machine learning library.  Even after that, there are a number of challenges with learning tactics since they take arguments and that can greatly expand your search space.</p>
<p><strong>rlCoP</strong></p>
<ul>
<li>Logic: Classical FOL</li>
<li>Search space: <ul>
<li>States: Connection tableau</li>
<li>Actions: Inference rules (cut-free so limited set of valid rules to choose from)</li>
</ul>
</li>
<li>Search algorithm:<ul>
<li>AlphaZero style Monte Carlo tree search (with learned policy/value)</li>
</ul>
</li>
<li>Machine learning method and training algorithm:<ul>
<li>Hand-engineered features fed into XGBoost</li>
<li>AlphaZero style reinforcement learning</li>
<li>It was given first order statements to solve from a list of problems. If it could solve them, then it was rewarded, else punished.  (This is not exactly true, especially for the policy.)</li>
</ul>
</li>
<li>Dataset: Miz40<ul>
<li>Only the statements, not the proofs.</li>
<li>It used RL to learn proofs.</li>
</ul>
</li>
<li>What prevents this from being applied to Lean?<ul>
<li>If used as a first order theorem prover, it would have to be ported from OCaml to Lean. (The most difficult would be the bindings to a machine learning tool to do XGBoost.)</li>
<li>If used as a tactic theorem prover,  the training method is very extensible to tactics and goals.  The main differences are:<ul>
<li>The search space with tactics isn’t necessarily cut-free so it can be quite larger, but it might be possible to fix a smaller subset of tactics (and tactic arguments).</li>
<li>One needs to redo the hand-engineered features (and obviously the RL training).</li>
<li>One needs a good diverse set of training problems of varying difficulty.  (Just theorem statements, not proofs.)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>TacticToe</strong></p>
<ul>
<li>System: HOL4 tactics</li>
<li>Search space:<ul>
<li>States: Lists of open goals (plus meta information such as how many times each tactic has been applied)</li>
<li>Actions: Tactics (but this is complicated since tactics have arguments and tactics may fail or do nothing)</li>
</ul>
</li>
<li>Search algorithm:<ul>
<li>AlphaZero style Monte Carlo tree search (with policy/value)</li>
<li>The policy and value cover special tactics like applying an ATP or applying tactics which take arguments.</li>
</ul>
</li>
<li>Machine learning method and training algorithm:<ul>
<li>Curated database of tactics</li>
<li>Hand engineered “predictor” features</li>
<li>“Learning” means creating and improving this database</li>
<li>There is a lot I don’t understand yet about the learning step</li>
<li>Policy / value are based on how similar the current tactic / goal is to what is in the database based on the hand-engineered predictor features.</li>
</ul>
</li>
<li>Dataset: <ul>
<li>“Human proofs” (I assume the HOL4 library, with proper proof recording)</li>
</ul>
</li>
<li>What prevents this from being applied to Lean?<ul>
<li>It is probably mostly just engineering, but there is a lot of engineering involved.</li>
<li>I don’t know if the differences in logic really matter.</li>
</ul>
</li>
</ul>
<p><em>GamePad</em></p>
<ul>
<li>System: Coq tactics</li>
<li>Search space:<ul>
<li>States: Lists of open goals</li>
<li>Actions: Tactics (they didn’t deal with the complicated case of the have tactic or the rewrite tactic which take arguments)</li>
</ul>
</li>
<li>Search algorithm:<ul>
<li>The GamePad baselines don’t have a proof search, but the whole point of GamePad it is a framework for one two build machine learning tools for Coq such as Monte Carlo tree search.</li>
<li>While they don’t do full theorem proving, they do predict tactics used in human proofs and proof evaluation (number of steps left in the proof) which could be used for a tree search algorithm.</li>
</ul>
</li>
<li>Machine learning method and training algorithm:<ul>
<li>Recursive tree neural networks learn embeddings (feature vectors encoding information) for terms, formulas, goals, etc.</li>
<li>Tried a number of machine learning methods (SVM, GRU, LSTM) for the prediction and evaluation tasks. </li>
<li>Trained with supervised learning</li>
</ul>
</li>
<li>Dataset: <ul>
<li>Coq Library, Feit Thompson</li>
</ul>
</li>
<li>What prevents this from being applied to Lean?<ul>
<li>This is closest to Lean in logic.  Again, it’s a lot of engineering.  </li>
<li>Also, there is no prover built yet.  This is more of a learning framework than a final product.  (The goal is for others to work in this framework and beat their baselines.)</li>
</ul>
</li>
</ul>
<p><em>HOList</em></p>
<ul>
<li>System: HOL Light tactics</li>
<li>Search space:<ul>
<li>States: Goal (set of subgoals if I am not mistaken)</li>
<li>Actions: Tactics (both tactic and premise argument)</li>
</ul>
</li>
<li>Search algorithm:<ul>
<li>Breath first search</li>
<li>Limit on the number of tactic actions from each goal</li>
<li>Tactics are ranked by neural network policy</li>
<li>Again, this baseline algorithm is designed to be improved by other users.</li>
</ul>
</li>
<li>Machine learning method and training algorithm:<ul>
<li>Neural network embeddings for goals and premises.  (I think they tried both convolutional NNs and WaveNet, but I don’t know for sure.)</li>
<li>Neural networks which rank tactics and tactic + premise pairs.  (Again, I’m not clear on the details.)</li>
<li>Trained with supervised learning first on human proof and then reinforcement learning.  (I’m not clear on the RL training details.)</li>
</ul>
</li>
<li>Datasets: <ul>
<li>HOL Light core, complex (as in complex arithmetic), and Flyspeck</li>
</ul>
</li>
<li>What prevents this from being applied to Lean?<ul>
<li>Again, it’s a lot of engineering.  </li>
<li>It could be possible to hook up their system to Lean in theory.  Of course the exact logic and tactics are different.</li>
</ul>
</li>
</ul>

<a name="166075620"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166075620" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166075620">Joseph Corneli (May 20 2019 at 11:06)</a>:</h4>
<p>Here are a couple references I've come across that look relevant to premise selection (in the context of proof synthesis).</p>
<p>A type-theoretic approach that could be germane to our style of working here:</p>
<p>Jan Bessai et al. Combinatory Logic Synthesizer. In Tiziana Margaria and Bernhard Steffen, editors, Leveraging Applications of Formal Methods, Verification and Validation. Technologies for Mastering Change, pages 26–40, Berlin, Heidelberg. Springer Berlin Hei- delberg, 2014.</p>
<p>Applications of contemporary ML tools to code:</p>
<p>Tal Ben-Nun et al. Neural Code Comprehension: A Learnable Representation of Code Semantics. In S. Bengio et al., editors, Advances in Neural Information Processing Systems 31, pages 3589–3601. Curran Associates, Inc., 2018.</p>

<a name="166863717"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/166863717" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#166863717">Jason Rute (May 29 2019 at 22:36)</a>:</h4>
<p>I’ve recently come across these three new papers on machine learning theorem proving in interactive theorem provers:</p>
<ul>
<li><a href="https://arxiv.org/abs/1905.09381" target="_blank" title="https://arxiv.org/abs/1905.09381">Learning to Prove Theorems via Interacting with Proof Assistants</a>  A theorem prover (ASTactic) and gym (CoqGym) for Coq.  (Separate project from GamePad.)  Trained on a very large collection of Coq projects.</li>
<li>These next two are new additions to the <a href="https://sites.google.com/view/holist/home" target="_blank" title="https://sites.google.com/view/holist/home">HOList</a> project for HOL Light which now has a nice summary of all their results at the top of the website.<ul>
<li><a href="https://arxiv.org/abs/1905.10006" target="_blank" title="https://arxiv.org/abs/1905.10006">Graph Representations for Higher-Order Logic and Theorem Proving</a>  An improved automated theorem prover using graph neural networks.  It is trained on human proofs.</li>
<li><a href="https://arxiv.org/abs/1905.10501" target="_blank" title="https://arxiv.org/abs/1905.10501">Learning to Reason in Large Theories without Imitation</a>  An improved reinforcement learning theorem prover trained without human proofs (but trained with human written theorem statements and uses standard HOL Light human engineered tactics).</li>
</ul>
</li>
</ul>

<a name="167625175"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/167625175" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#167625175">Bryan Gin-ge Chen (Jun 08 2019 at 00:32)</a>:</h4>
<p>I haven't watched it yet, but here's an interview with Christian Szegedy of the Google Brain team. Presumably he talks about some of the papers mentioned above. <a href="https://www.youtube.com/watch?v=p_UXra-_ORQ" target="_blank" title="https://www.youtube.com/watch?v=p_UXra-_ORQ">https://www.youtube.com/watch?v=p_UXra-_ORQ</a></p>
<div class="youtube-video message_inline_image"><a data-id="p_UXra-_ORQ" href="https://www.youtube.com/watch?v=p_UXra-_ORQ" target="_blank" title="https://www.youtube.com/watch?v=p_UXra-_ORQ"><img src="https://i.ytimg.com/vi/p_UXra-_ORQ/default.jpg"></a></div>

<a name="167696394"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/167696394" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#167696394">Jason Rute (Jun 09 2019 at 11:41)</a>:</h4>
<p><span class="user-mention" data-user-id="123965">@Bryan Gin-ge Chen</span> Thanks for sharing!  It was really interesting!</p>
<p>For those who prefer to read, here is <a href="https://scale.ai/interviews/christian-szegedy/transcript" target="_blank" title="https://scale.ai/interviews/christian-szegedy/transcript">a (computer generated) transcript of the video</a>.  It's a non-technical, high-level vision talk and is very accessible to the Lean community.  </p>
<ul>
<li>The first part of the video is about how Christian got into deep learning about about his earlier work (which is quite influential in the field, batch-normalization, inception architecture, and adversarial examples).  </li>
<li>At 14:26, they start talking about AI and formalization and Szegedy explains his motivation which is high level automated code generation. </li>
<li>At 19:33 the interviewer challenges Szegedy about why he thinks AI mathematics is at all tractable.  Szegedy has some interesting thoughts and moreover has a much bigger vision than I realized.  He thinks the only way to make this tractable is to simultaneously work on automated formalization of books and papers while also working on automated theorem proving.  Both will strengthen the other (and have huge consequences in natural language understanding if successful).  </li>
<li>At 26:43 they talk about the HOList project (but not by name), and what papers are coming next in a few weeks from his lab.  Rather than using a fix search algorithm like beam search, the AI agent will handle the searching as well.  (I've been thinking a lot about this same thing recently.  MCTS works really well in games since even small differences in game states can be exploited by an opponent, but in theorem proving, there are many paths to the goal and exploring one branch will tell you a lot about similar branches in a way that beam search or MCTS don't handle.)</li>
</ul>

<a name="171889226"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/171889226" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#171889226">Jason Rute (Jul 28 2019 at 13:14)</a>:</h4>
<p>ProverBot9001 is yet another work using machine learning to prove theorems for Coq.  <a href="https://arxiv.org/abs/1907.07794" target="_blank" title="https://arxiv.org/abs/1907.07794">Generating Correctness Proofs with Neural Networks</a>.  The code can be found at <a href="https://github.com/UCSD-PL/proverbot9001" target="_blank" title="https://github.com/UCSD-PL/proverbot9001">https://github.com/UCSD-PL/proverbot9001</a> .  The paper is pretty well written.  They have made it clear that their approach proves more theorems overall than CoqGym/ASTactic and CoqHammer (see <a href="https://arxiv.org/pdf/1907.07794.pdf#page=20" target="_blank" title="https://arxiv.org/pdf/1907.07794.pdf#page=20">Figure 15</a>).  There are still a number of possible improvements to make it much better.   I suspect that the work of Szegedy’s lab, if applied to Coq, would probably give much better results overall, but this is hard to say for sure since HOL Light and Coq are different systems with different logics, tactics, and libraries.</p>

<a name="177462716"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177462716" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177462716">Jason Rute (Oct 06 2019 at 14:09)</a>:</h4>
<p>I haven’t posted any updates on AI and theorem proving in a while.  Here are some:</p>

<a name="177462760"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177462760" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177462760">Jason Rute (Oct 06 2019 at 14:10)</a>:</h4>
<p>Just over a month ago, Szegedy posted a manifesto called <a href="https://storage.cloud.google.com/deepmath/Autoformalization.pdf?organizationId=433637338589" target="_blank" title="https://storage.cloud.google.com/deepmath/Autoformalization.pdf?organizationId=433637338589">A Promising Path Towards Autoformalization and General Artificial Intelligence</a>.  It is really interesting and provocative—if a bit challenging to read.  (Also, it mentions Lean!)  His master vision is to simultaneously build powerful AI autoformalization and AI automated theorem proving by training both tasks in lock-step.  The main idea is to take <strong>images</strong> of math papers and to encode them as vectors in R^n that represent a theorem to prove.  (As weird as this sounds to go to R^n instead of the symbols of the theorem to prove, it is a common practice in AI, especially machine translation, to “embed” the input, in this case informal math papers, into an intermediate latent space R^n before translating it into the final symbolic space.)  Then one uses these vectors to guide proving new theorems, given theorems already proven.  This is a boot-strapping process, where the autoformalization procedure gets positive reinforcement feedback when its “translations” lead to a new proof, and in turn these new proofs provide training data for the theorem prover.</p>

<a name="177462827"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177462827" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177462827">Jason Rute (Oct 06 2019 at 14:12)</a>:</h4>
<p>While I think the plan is incredibly ambitious, Szegedy explains in Section 7 how one would start to build smaller prototypes of the system parts.  If I might be so bold as to suggest another addition to that section, (<span class="user-mention" data-user-id="239426">@Christian Szegedy</span> <span class="user-mention" data-user-id="239408">@Sarah Loos</span>  <span class="user-mention" data-user-id="217806">@Markus Rabe</span> ), instead of working with (images of) informal mathematics papers to begin with, they could use libraries of formal mathematics (Mizar, MetaMath, and maybe even raw Lean, Coq, Isabelle, etc. code ) instead, where the latter is given only as unaligned sequences of symbols (or trees/graphs of tokens).  While they wouldn’t be developing informal-to-formal translation yet, they would be developing formal-to-formal translation between theorem provers without a need to align symbols manually or get into the complicated inter-workings of the source logical language.  (And it would still provide useful training data for the automated theorem prover.)</p>

<a name="177462833"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177462833" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177462833">Jason Rute (Oct 06 2019 at 14:12)</a>:</h4>
<p>In other news, Szegedy’s lab recently posted a paper on <a href="https://arxiv.org/pdf/1909.11851v1.pdf" target="_blank" title="https://arxiv.org/pdf/1909.11851v1.pdf">Mathematical Reasoning in Latent Space</a>.  They showed that you can embed a mathematical statement into R^n (latent space) and then from that embedding alone, do multiple steps of symbolic rewriting (in the sense of a rewriting tactic).  This is important because one of the most expensive parts of tools like HOList (or even AlphaGo) is to go from the symbolic representation (e.g. a formula, a go board) to the prediction of the next step in the search.  This prediction function is usually composed of two parts:  (1) A large domain-specific neural network (e.g. a graph neural network or a convolutional neural network) which embeds the symbolic problem into a vector in latent space.  (2) A small neural network which takes this embedding and computes the result, which in a search algorithm is the next move to apply (e.g. the next tactic to apply).  Now if it is possible to also “perform” that move in the latent space, then there is no need to constantly calculate the embedding at each step.  Moreover, having general purpose precomputed embeddings is a common way to speed up AI training for specific applications.  For example, a lot of work is spent in machine learning on creating pre-trained embeddings for English words and for images of everyday objects.  Szegedy’s work shows that one can use the mechanism of symbolic rewriting to automatically compute embeddings of (HOL) formulas automatically.</p>

<a name="177462839"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177462839" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177462839">Jason Rute (Oct 06 2019 at 14:13)</a>:</h4>
<p>Last, on a different note, one system I neglected to mention previously is <a href="https://arxiv.org/pdf/1608.02644.pdf" target="_blank" title="https://arxiv.org/pdf/1608.02644.pdf">Holophrasm</a> which is an older AI-based theorem-prover for MetaMath by Daniel Whalen.  A new paper extending Holophrasm is on the topic of <a href="https://openreview.net/pdf?id=BJxiqxSYPB" target="_blank" title="https://openreview.net/pdf?id=BJxiqxSYPB">Learning to prove theorems by learning to generate theorems</a>.  The accuracy of this new paper is still fairly low, ~20% of MetaMath theorems are proven, but given that MetaMath has no automation or tactics, this might actually be pretty good.  (As usual, the lack of uniform benchmarks makes it challenging to compare ML techniques across different theorem provers.  And of course, raw accuracy numbers are not very meaningful to practitioners.)</p>

<a name="177469475"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177469475" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177469475">Luca Seemungal (Oct 06 2019 at 17:37)</a>:</h4>
<p>Is it possible to save comments for later reference on zulip?</p>

<a name="177469702"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177469702" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177469702">Johan Commelin (Oct 06 2019 at 17:45)</a>:</h4>
<p><span class="user-mention" data-user-id="221895">@Luca Seemungal</span> Click the little star (which appears if you hover over the message, in the top right corner). Keyboard shortcut: <code>*</code></p>

<a name="177469892"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177469892" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177469892">Luca Seemungal (Oct 06 2019 at 17:50)</a>:</h4>
<p>Ah cheers</p>

<a name="177471352"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177471352" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177471352">Reid Barton (Oct 06 2019 at 18:29)</a>:</h4>
<p>Do you mean literal images as in arrays of grayscale values?</p>

<a name="177472316"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177472316" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177472316">Bryan Gin-ge Chen (Oct 06 2019 at 18:58)</a>:</h4>
<p>From Section 6: "A Proposed Path to Autoformalization", (page 11 of the PDF):</p>
<blockquote>
<p>One engineering question is how to represent informal mathematical content, that is mathematical papers and text books we want to formalize automatically. The straightforward looking path would be to represent them textually, for example by a sequence of unicode characters. This might work well for use cases that do not require the understanding of formulas, diagrams and graphs. However mathematical content is heavily based on the use of formulas and also diagrams and geometric illustrations might play an important role in informing the reader. Therefore the best path seems to rely on images instead of textual representation. Given that humans work from the same representation, this can preempt a lot of unexpected failure modes and engineering that would go into reconciling various types of textual representations of the same input.</p>
</blockquote>

<a name="177472957"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177472957" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177472957">Reid Barton (Oct 06 2019 at 19:17)</a>:</h4>
<p>Thanks Bryan, my phone isn't displaying the pdf for some reason.</p>

<a name="177473198"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177473198" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177473198">Bryan Gin-ge Chen (Oct 06 2019 at 19:24)</a>:</h4>
<p>Yeah, I had to log into a google account to access it. Let me just attach the file to Zulip here for convenience: <a href="/user_uploads/3121/lWKHE1MCcJ1ZwiF2poPoJckC/Autoformalization.pdf" target="_blank" title="Autoformalization.pdf">Autoformalization.pdf</a></p>

<a name="177473257"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177473257" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177473257">Reid Barton (Oct 06 2019 at 19:26)</a>:</h4>
<p>Now acrobat can't open it because it's not logged in to zulip, instead :)</p>

<a name="177473280"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177473280" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177473280">Reid Barton (Oct 06 2019 at 19:27)</a>:</h4>
<p>Okay, I managed to get it.</p>

<a name="177475212"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177475212" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177475212">Tim Daly (Oct 06 2019 at 20:22)</a>:</h4>
<p>Quoting from the Szegedy paper: "Still, everything that can be specified precisely can be considered as mathematics and  everything  we  can  talk  about  precisely  is  what  we  can  talk  about  it  by mathematical arguments.  Therefore, mathematics is the language of all things specified formally."</p>
<p>This is a form of hasty generalization. </p>
<p>The mathematicians I have worked with spent a lot of time "hand waving" at a solution, wrote psuedo-formal attempts, and got "debated" into slightly more formal positions, usually by being more precise in their definitions. The "definition" phase is essentially contructing a new "type" so that they could restrict their domain enough to get a sound and complete map to their solution domain. That, in my experience, is "mathematics"., i.e. what a mathematician does.</p>
<p>Computational mathematics takes the formalized definitions and theorems and tries to construct a formal proof from primary axioms. "Everything that can be specified precisely can be considered as mathematics" is a good premise but "mathematics is the language of all things specified formally" does not follow as a conclusion.</p>

<a name="177475264"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177475264" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177475264">Christian Szegedy (Oct 06 2019 at 20:24)</a>:</h4>
<blockquote>
<p>they could use libraries of formal mathematics (Mizar, MetaMath, and maybe even raw Lean, Coq, Isabelle, etc. code ) instead, where the latter is given only as unaligned sequences of symbols (or trees/graphs of tokens).  While they wouldn’t be developing informal-to-formal translation yet, they would be developing formal-to-formal translation between theorem provers without a need to align symbols manually or get into the complicated inter-workings of the source logical language.  (And it would still provide useful training data for the automated theorem prover.)</p>
</blockquote>
<p>Yes we were considering this, but it is unclear at this point whether it would be an unnecessary detour or a useful proof of concept.</p>
<p>What we plan to do is the (presumably much simpler) task of reconstructing larger parts of our theorem library purely from their semantic embeddings. Even that could be made incrementally easier and or harder: in the simplest case the system has access to the original embedding model. The next step if it needs to reconstruct it, and the third level if we inject some extra noise into those embeddings as well. </p>
<p>Without getting too technical, I would like to thank Jason for the great and insightful summary. While our project is very ambitious, it is more inspiring to have a high level long term vision and work towards it, rather than doing disconnected random research. Doing so enables us to concentrate on fundamental basic ideas that could actually matter in the long run. Also it forces us to come up with simpler versions of the final system and test them in isolation, leading to interesting ideas like the one you mention above.</p>

<a name="177475509"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177475509" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177475509">Christian Szegedy (Oct 06 2019 at 20:32)</a>:</h4>
<blockquote>
<p>The mathematicians I have worked with spent a lot of time "hand waving" at a solution, wrote psuedo-formal attempts, and got "debated" into slightly more formal positions, usually by being more precise in their definitions. The "definition" phase is essentially contructing a new "type" so that they could restrict their domain enough to get a sound and complete map to their solution domain. That, in my experience, is "mathematics"., i.e. what a mathematician does.</p>
</blockquote>
<p>You can still debate them into doing so, since they agree that it should be possible.</p>

<a name="177476096"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177476096" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177476096">Tim Daly (Oct 06 2019 at 20:48)</a>:</h4>
<p>The deepest mathematics I've ever tried was on two problems: The Twin Primes Conjecture and The Andrews-Curtis Conjecture. Both of them are "formally specified" but really require whole new areas of mathematics. As I think Buzzard pointed out in one of his talks, some problems get solved because a much more general problem is solved and the initial problem is just a special case.<br>
(<a href="http://daly.axiom-developer.org/TimothyDaly_files/ACConjecture/index.html" target="_blank" title="http://daly.axiom-developer.org/TimothyDaly_files/ACConjecture/index.html">http://daly.axiom-developer.org/TimothyDaly_files/ACConjecture/index.html</a>)</p>
<p>It may be possible to "pattern recognize" methods of proof but this is just defining "tactics". I don't see how you can "pattern recognize" definitions though. What would a "tactic" for constructing a definition look like? Indeed, if you feed definitions to a deep learning system, what would you expect it to recognize?</p>

<a name="177479116"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177479116" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177479116">Tim Daly (Oct 06 2019 at 22:25)</a>:</h4>
<p>Barry Mazur gave a lecture (<a href="https://video.ethz.ch/speakers/bernays/2018.html" target="_blank" title="https://video.ethz.ch/speakers/bernays/2018.html">https://video.ethz.ch/speakers/bernays/2018.html</a>) and discusses the role of definition at about the 25 minute mark.</p>

<a name="177483424"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177483424" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177483424">Christian Szegedy (Oct 07 2019 at 00:51)</a>:</h4>
<blockquote>
<p>It may be possible to "pattern recognize" methods of proof but this is just defining "tactics". I don't see how you can "pattern recognize" definitions though. What would a "tactic" for constructing a definition look like? Indeed, if you feed definitions to a deep learning system, what would you expect it to recognize?</p>
</blockquote>
<p>I think this relies on a misunderstanding of our notion of tactic, also of  the role of "pattern recognizing", etc.</p>
<p>In our setup "tactic" just refers to one "proof step" using the HOL Light proof assistant.</p>
<p>In the long run, we want to explore mathematics, but in a way that is still useful for proving theorems in our seed corpus (the seed conjectures given by humans). On the way the system should maintain and extend a database of definitions and conjectures. Create new definitions, either by abstracting common patterns in existing definitions or proofs or by just coming up with intriguing new objects, perhaps those that serve as counter examples of others. </p>
<p>Both definition and conjecture creation can be viewed as a special case of generative modeling. In the case of definitions you try to generate new notions that helps to compress the existing corpus of mathematics, e.g. making existing statements special cases or just simplifiying the proofs. In the case of conjectures, you try to create statements that would be either be helpful for proving other conjectures or those that could generalize existing statements (again: compression).</p>

<a name="177486340"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177486340" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177486340">Jason Rute (Oct 07 2019 at 02:25)</a>:</h4>
<blockquote>
<p>it is more inspiring to have a high level long term vision and work towards it, rather than doing disconnected random research</p>
</blockquote>
<p>I agree.  One can compare it to DeepMind’s AlphaStar project to beat StarCraft II.  As the AlphaStar project and the subsequent commentary shows, different people can look at the same results with very different levels of optimism.  The pessimistic view is that deep learning is just function approximation and pattern recognition and this isn’t close to sufficient for success on StarCraft II.  Moreover, any success AlphaStar does have is just due to the non-human advantages of computers (many-lifetimes worth of playing experience, fast brute force search, perfect accuracy, and no mistakes).  It can’t plan, strategize, show creativity, or understand the game.   And those in this camp are quick to point out how even with its unfair advantages, <a href="https://www.reddit.com/r/MachineLearning/comments/d13yex/r_deepmind_starcraft_2_update_alphastar_is/" target="_blank" title="https://www.reddit.com/r/MachineLearning/comments/d13yex/r_deepmind_starcraft_2_update_alphastar_is/">AlphaStar is consistently being beat by humans</a>.  I hear the same pessimism about applying deep learning to mathematics: all deep learning can do is recognize patterns in proofs.  It can’t understand math, make definitions, or show the level of creativity of a mathematician.</p>

<a name="177486375"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177486375" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177486375">Jason Rute (Oct 07 2019 at 02:26)</a>:</h4>
<p>I would both agree narrowly that these are valid concerns, but offer a much more optimistic viewpoint.  In StarCraft II, a lot of success has been made by successfully combining off-the-shelf tools from other areas of AI research.  For example, LSTMs and attention-based mechanisms are both tools heavily used in natural language processing, and population-based training is a very old idea in machine learning inspired by biological evolution and diversity.  Even if AlphaStar isn’t perfect, it is still amazing how far we’ve come and how general the techniques are that it employs.  A philosopher can argue whether it shows “long term planning” or “creativity”, but it does accomplish something more human-like than other algorithms and can readily be applied to new problems.  I think the same story will hold in computer mathematics.  We have barely begun to explore the possibilities of applying existing deep learning techniques to theorem proving and autoformalization, and the little existing research done by a select few researchers already has shown real promise!  Rather than pessimistically saying this will never work because, say, we don’t have a solid plan for how to teach the agent to make new definitions, let’s see how far the current deep learning techniques take us.  And unlike AlphaStar, if the result of this program is only a halfway decent automated theorem prover which can autoformalize some of the existing literature, that is a great initial step with very real value to mathematics and industry!</p>

<a name="177486390"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/AI%20and%20theorem%20proving/near/177486390" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/113488general/41431AIandtheoremproving.html#177486390">Jason Rute (Oct 07 2019 at 02:26)</a>:</h4>
<p>Moreover, my optimism doesn’t stop there.  Deep learning research is far from fizzling out, and there seems to be <a href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30061-0" target="_blank" title="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30061-0">good arguments</a> that the human mind could well use something like deep reinforcement learning to learn both at the level of milliseconds and millennia (the later via evolution).  Moreover, as Christian pointed out, deep learning also provides, through say reinforcement learning and generative modeling, ways to create entirely new and novel information. So I think we are on the right track, even if there is still decades of research needed.  As automated neural mathematics reaches the limit of the current techniques in deep learning, other research groups in AI (e.g. machine translation, game play, or robotics) may already have solved some of the problems we face.  If not, computer mathematics could very well be the testbed needed to bring in powerful ideas from human intelligence into AI.</p>


{% endraw %}

{% include archive_update.html %}