---
layout: archive
title: Lean Prover Zulip Chat Archive
permalink: archive/208328IMOgrandchallenge/00479F2F.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/index.html">IMO-grand-challenge</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html">F2F</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">

{% raw %}
<a name="175125031"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175125031" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175125031">Johan Commelin (Sep 07 2019 at 04:54)</a>:</h4>
<p>I just read on the website:</p>
<blockquote>
<p>To eliminate the need for human judges, we propose the formal-to-formal (F2F) variant of the IMO: the AI receives a formal representation of the problem (in the Lean Theorem Prover), and is required to emit a formal (i.e. machine-checkable) proof. We are working on a proposal for encoding IMO problems in Lean and will seek broad consensus on the protocol.</p>
</blockquote>
<p>Doesn't this mean that human "judges" will not be able to say why they should trust Lean's solution, and why it deserves a gold medal?</p>

<a name="175125076"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175125076" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175125076">Johan Commelin (Sep 07 2019 at 04:54)</a>:</h4>
<p>Of course I still think this is an awesome challenge.</p>

<a name="175125085"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175125085" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175125085">Johan Commelin (Sep 07 2019 at 04:55)</a>:</h4>
<p>So don't take this complaint too serious <span aria-label="stuck out tongue wink" class="emoji emoji-1f61c" role="img" title="stuck out tongue wink">:stuck_out_tongue_wink:</span></p>

<a name="175125031"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175125031" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175125031">Johan Commelin (Sep 07 2019 at 04:54)</a>:</h4>
<p>I just read on the website:</p>
<blockquote>
<p>To eliminate the need for human judges, we propose the formal-to-formal (F2F) variant of the IMO: the AI receives a formal representation of the problem (in the Lean Theorem Prover), and is required to emit a formal (i.e. machine-checkable) proof. We are working on a proposal for encoding IMO problems in Lean and will seek broad consensus on the protocol.</p>
</blockquote>
<p>Doesn't this mean that human "judges" will not be able to say why they should trust Lean's solution, and why it deserves a gold medal?</p>

<a name="175125076"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175125076" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175125076">Johan Commelin (Sep 07 2019 at 04:54)</a>:</h4>
<p>Of course I still think this is an awesome challenge.</p>

<a name="175125085"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175125085" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175125085">Johan Commelin (Sep 07 2019 at 04:55)</a>:</h4>
<p>So don't take this complaint too serious <span aria-label="stuck out tongue wink" class="emoji emoji-1f61c" role="img" title="stuck out tongue wink">:stuck_out_tongue_wink:</span></p>

<a name="175132944"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175132944" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175132944">Patrick Massot (Sep 07 2019 at 09:16)</a>:</h4>
<p>I guess the IMO judges won't like this "eliminate the need for human judges". I'm sure you can explain the idea using a less aggressive phrasing. When talking to colleagues about formal maths, I've noticed there are always some people who feel threatened and react defensively. I think they shouldn't feel like this, but most mathematicians are still human beings, so they don't always act rationnaly...</p>

<a name="175136300"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175136300" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175136300">Jason Rute (Sep 07 2019 at 11:00)</a>:</h4>
<p>Yes, I think the motivation is set up in a confusing way.  This is more of a computer IMO instead of a computer-judged IMO.  As an analogy, think computer go/chess/bridge.  The key is not that you are replacing the original IMO competition with computer judges, but making a computer variant which naturally is judged by a computer proof checker.</p>

<a name="175136828"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175136828" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175136828">Jason Rute (Sep 07 2019 at 11:17)</a>:</h4>
<p>When I first read the webpage, I thought this was humans (probably not high school students) writing proofs in Lean.  It took me another read to realize it was computers writing proofs in Lean.  (But this might have just been based on my having seen others here talk about solving IMO problems in Lean.)</p>

<a name="175140808"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175140808" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175140808">Daniel Selsam (Sep 07 2019 at 13:28)</a>:</h4>
<blockquote>
<p>Doesn't this mean that human "judges" will not be able to say why they should trust Lean's solution, and why it deserves a gold medal?</p>
</blockquote>
<p><span class="user-mention" data-user-id="112680">@Johan Commelin</span> Hi Johan. First, I'll say that the rules are very much up for debate. The current proposal reflects two competing desiderata. On one hand, we want people to agree on the scoring system ahead of time, and we fear that it might be hard to preempt post-test controversy if we rely on human judges instead of the Lean kernel. On the other hand, we want to honor the spirit of the (traditional) IMO and only accept high-level proofs. If it happened that a fancy decision procedure could get Gold on the IMO with incomprehensible low-level proofs, I would probably consider that more a quirk of the test than progress in AI. The current rules allow lower-level proofs than humans could possibly provide, but type-checking in 10 minutes given only the acceptable background math does limit how low-level a proof can be. If a team wanted their AI to use e.g. Sturm sequences, the proofs they submit would need to include formally verified versions of all relevant claims, all of which must be type-checkable within the 10 minute time limit. To some extent we can enforce higher level proofs even in the F2F setting by just decreasing the amount of time allowed for type-checking.</p>

<a name="175141342"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175141342" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175141342">Daniel Selsam (Sep 07 2019 at 13:45)</a>:</h4>
<blockquote>
<p>I guess the IMO judges won't like this "eliminate the need for human judges". I'm sure you can explain the idea using a less aggressive phrasing. When talking to colleagues about formal maths, I've noticed there are always some people who feel threatened and react defensively. I think they shouldn't feel like this, but most mathematicians are still human beings, so they don't always act rationnaly...</p>
</blockquote>
<p><span class="user-mention" data-user-id="110031">@Patrick Massot</span> Thanks for mentioning this. It never occurred to me. I will think about how to clarify the motivations. Also, see discussion a few posts up about whether we even want machine-checkable proofs.</p>

<a name="175141453"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175141453" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175141453">Daniel Selsam (Sep 07 2019 at 13:48)</a>:</h4>
<blockquote>
<p>Yes, I think the motivation is set up in a confusing way.  This is more of a computer IMO instead of a computer-judged IMO.  As an analogy, think computer go/chess/bridge.  The key is not that you are replacing the original IMO competition with computer judges, but making a computer variant which naturally is judged by a computer proof checker.</p>
</blockquote>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> Hi Jason. Funny, this interpretation never occurred to me. I will add a sentence to preempt it.</p>

<a name="175160427"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175160427" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175160427">Scott Morrison (Sep 07 2019 at 23:43)</a>:</h4>
<p>Presumably the intention is that solutions can use mathlib; is compiling the needed parts of mathlib included in the 10 minutes? (That seems like a terrible interpretation to me.)</p>

<a name="175238786"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175238786" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175238786">Jason Rute (Sep 09 2019 at 13:02)</a>:</h4>
<p><span class="user-mention" data-user-id="230999">@Daniel Selsam</span> I'm curious who the intended audience for this challenge is.  For example, do you think you will be able to get major players involved in this competition, from the ITP, ATP, and/or AI communities?  Do you imagine the submissions will come from large teams or individuals?  Do you think you will get lots of submissions or just a few?  Are there other similar competitions that we can compare this to?</p>

<a name="175240239"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175240239" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175240239">Daniel Selsam (Sep 09 2019 at 13:21)</a>:</h4>
<blockquote>
<p>Presumably the intention is that solutions can use mathlib; is compiling the needed parts of mathlib included in the 10 minutes? (That seems like a terrible interpretation to me.)</p>
</blockquote>
<p><span class="user-mention" data-user-id="110087">@Scott Morrison</span> Hi Scott, good question. We imagine there being one Lean library for the background math that will be type-checked once, and AI proofs can use theorems in this library without it counting against the type-check time-limit. However, the background math library will not include all of mathlib, and instead will only include (a) theorems that human competitors are allowed to cite without proof and (b) basic things that are too obvious for human competitors to even state. Does this sound reasonable to you?</p>

<a name="175248777"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175248777" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175248777">Daniel Selsam (Sep 09 2019 at 14:51)</a>:</h4>
<blockquote>
<p>@Daniel Selsam I'm curious who the intended audience for this challenge is. For example, do you think you will be able to get major players involved in this competition, from the ITP, ATP, and/or AI communities? Do you imagine the submissions will come from large teams or individuals? Do you think you will get lots of submissions or just a few? Are there other similar competitions that we can compare this to?</p>
</blockquote>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span>  I think the best analogy is chess. It was a northstar for decades before Deep Blue. I hope researchers from many different fields think about what it would take to win gold, reflect on the limitations of their existing tools, and develop new approaches over time. I don't expect any submissions until 2021 at the earliest.</p>

<a name="175290725"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175290725" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175290725">Scott Morrison (Sep 09 2019 at 22:50)</a>:</h4>
<p>Ooof, building a custom library seems a lot of work. Why not just start with "all-of-mathlib" as the spec? Most of mathlib is completely irrelevant to IMO problems, and its irrelevance saves you the effort of cutting it out by hand. :-)</p>

<a name="175312106"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/F2F/near/175312106" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/208328IMOgrandchallenge/00479F2F.html#175312106">Mario Carneiro (Sep 10 2019 at 07:09)</a>:</h4>
<p>It doesn't seem unreasonable to me to allow all of mathlib but retain the privilege to reject a solution that uses some cheating theorem (assuming you didn't think to blacklist it in the first place). TBH it's a lot more interesting if you don't curate the library since library relevance filtering is a useful skill.</p>


{% endraw %}

{% include archive_update.html %}