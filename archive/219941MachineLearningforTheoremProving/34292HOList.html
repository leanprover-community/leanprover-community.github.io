---
layout: archive
title: Lean Prover Zulip Chat Archive
permalink: archive/219941MachineLearningforTheoremProving/34292HOList.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/index.html">Machine Learning for Theorem Proving</a>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html">HOList</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com">

{% raw %}
<a name="185555422"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185555422" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185555422">Jason Rute (Jan 14 2020 at 01:01)</a>:</h4>
<p><a href="https://sites.google.com/view/holist/home" target="_blank" title="https://sites.google.com/view/holist/home">DeepHOL/HOList</a> is Google Research neural-based automatic theorem prover for HOL Light.  A number of us have had deep discussions about it, how it works, and some of its design decisions.  Here are some highlights:</p>
<ul>
<li><span class="user-mention" data-user-id="213234">@Aaron Hadley</span>  and his team at UCF have made a great notebook demonstrating the "front end" Python API how to extend HOList to use other machine learning models <a href="https://github.com/aahadley/deepmath-jupyter/blob/master/HOLJup.ipynb" target="_blank" title="https://github.com/aahadley/deepmath-jupyter/blob/master/HOLJup.ipynb">here</a> and they also added a <a href="https://github.com/aahadley/deepmath-jupyter/blob/master/TutorialPaper.pdf" target="_blank" title="https://github.com/aahadley/deepmath-jupyter/blob/master/TutorialPaper.pdf">tutorial</a>.</li>
<li>If you are more interested in how DeepHOL (the neural prover) communicates with HOList (the modified from of HOL Light), here is a <a href="https://github.com/jasonrute/holist-communication-example" target="_blank" title="https://github.com/jasonrute/holist-communication-example">project of mine</a> which fleshes out the backend API.  In particular, <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">this notebook</a> walks you through the gRPC API.</li>
<li>It should be noted that a lot of the backend API is not used in the front end API.  For example, currently DeepHOL can't supply term parameters to tactics.  But it can choose tactics and choose theorem parameters (premise selection).</li>
<li>If anyone is interesting in hooking up Lean (or any other ITP) to DeepHOL, <a href="https://gist.github.com/jasonrute/00109af2bdc0974d2e8e79faf26ba556" target="_blank" title="https://gist.github.com/jasonrute/00109af2bdc0974d2e8e79faf26ba556">here</a> is a very preliminary best guess at what it would take to do it after talking with <span class="user-mention" data-user-id="217806">@Markus Rabe</span> at Google.</li>
</ul>

<a name="185555480"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185555480" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185555480">Jason Rute (Jan 14 2020 at 01:02)</a>:</h4>
<p>I know there are still a lot of questions about HOList (like why it uses s-expressions).  Feel free to discuss here.</p>

<a name="185575109"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185575109" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185575109">Stanislas Polu (Jan 14 2020 at 08:49)</a>:</h4>
<p>On the question of S-expression, I think that we went to the bottom of it through various private discussions. Pretty-printed HOL-light expressions which are appealing because they are close to what a human formalizing a proof would use are unfortunately ambiguous. The parser supports type annotation for human to disambiguate term types when coding in HOL Light, but unfortunately the pretty-printer is destructive such that <code>pretty_print o parse</code> is not the identity.</p>
<p>S-expressions are unambiguous as they are a natural way to marshal the in-memory representation of HOL Light terms (with every variable/constant being explicitly typed).</p>
<p>Ideally for some ML application, having compact representations is useful. Theoretically we could record the top-level semi-typed parsable theorem and term expressions and have them appear in proof logs as tactics arguments but that's probably not practical because hol-light starts by turning these expressions into in-memory representations, destroying the disambiguated human-provided terms.</p>
<p>Hope this context is useful!</p>

<a name="185593684"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185593684" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185593684">Jason Rute (Jan 14 2020 at 13:07)</a>:</h4>
<p>I think to take a step back, we have to acknowledge that s-expressions are used in 2.5 different ways in HOList.</p>
<ul>
<li>They are used as a serialization method to send HOL Light terms back and forth between HOList and DeepHOL (again, see my <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">"backend" walkthrough of HOList/DeepHOL</a>.)  This is sort of natural since the terms are algebraic data structures and s-expressions are natural for capturing such algebraic data structures.  This would generalize to any formal logic I can think of, making it sort of language neutral (before training).  However, I can also imagine one could use other serialization methods.  One could have used JSON or gRPC (which naturally translates to JSON) as the serialization method as well.  <span class="user-mention" data-user-id="246156">@Brando Miranda</span> has asked about JSON and said that Emilio at <a href="https://github.com/ejgallego/coq-serapi" target="_blank" title="https://github.com/ejgallego/coq-serapi">Serapi/Coq</a> was thinking about switching from s-expressions to JSON.  In some sense I don't think it matters much here as long as one uses a lossless encoding which is easy to parse.  (And in this case, these s-expressions are extremely easy to parse into whatever form one wants.)</li>
<li>They are also used as the text entered into the neural network model.  If one is using a pure sequence input model like an RNN or wavenet, then I think the idea is that you would plug the s-expression in as is (except one-hot encoding every token first?).  Or if one was using a tree or graph NN, then one naturally parses the s-expression into that tree or graph.  <span class="user-mention" data-user-id="249373">@Stanislas Polu</span> has lamented that the current s-expressions are probably too long for an RNN and has suggested shorter encodings.  Again, I think one has full freedom to play around with other representations.  I can think of many.  On the most compact side is to use the compact representation from the HOLStep data set.  It throws away types.  It uses polish notation.  And it uses skolemization and DeBruin indices for quantifiers and variables.  This however might be too compact.  HOList has found (from taking with Markus) that variable names matter a lot.  Another compact-ish approach would be to simulate the HOL Light pretty printer, but maybe add a few extra things.  It wouldn't be hard to get the parentheses the same as HOL Light.  As for types, the HOL Light pretty printer throws them away, but I think one might want to keep them for quantifiers and lambdas only.  Now, intermediate goals might not have any quantifiers, but one could borrow notation from say Lean and write something like this for an intermediate goal <code>(n: nat), (m: nat) |- = (num_add m n) (num_add n m)</code>.  It is hard to know what would work best without experimentation.  I've suggested that rather than trying this all out on HOList, it might be better to experiment first with some of the different string representations with different neural network models on HOLStep first since it is an easier to train dataset.  We would be looking for something which is quick to run but also does well on the task.  Since it is so up in the air what a good string input is, I think it wouldn't make sense to encode it into the HOList/DeepMath interface.  Instead, s-expressions work nice as a loss-less encoding which could be tweaked into something else when needed.</li>
<li>Last, one is also using these s-expressions as some sort of semi-human-readable term representation.  This is needed for debugging and understanding the outputs.  Again, the programmer is free to clean up the formula a bit for debugging, but most of the current HOList printouts use these s-expressions.</li>
</ul>
<p>So in summary, s-expressions try to be everything to everyone.  While in practice they might fail at that, they are pretty easy to parse and turn into something else.  The only exception is that the HOL Light pretty printed expressions are a bit complicated to 100% reproduce, but one can come close.  If it is important to have the exact pretty printed expressions, one could build that as another server call into the gRPC interface.  Get me the pretty printed version of this s-expression.</p>

<a name="185607167"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185607167" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185607167">Markus Rabe (Jan 14 2020 at 15:36)</a>:</h4>
<p>The response to any apply tactic request should already include the pretty printed version of the terms (as well as the s-expression, of course). Also all the theorem in the theorem database should have a pretty printed field in their proto.</p>

<a name="185624371"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185624371" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185624371">Christian Szegedy (Jan 14 2020 at 18:29)</a>:</h4>
<p>Our first models were convolutional networks that take the  tokenized s-expression (with types) as input. We have removed the parenthesis as well, as it is redundant, but makes parsing of the expressions a bit easier (esp. for humans). </p>
<p>We have tried to train sequence models on the pretty printed output as well, but it yielded inferior results to the models taking s-expressions as input.</p>
<p>Our graph-neural networks uses subexpression-sharing (still containing) which makes the input significantly shorter</p>
<p>Using JSON would have had the disadvantage that we would have needed a JSON parser in our Google internal version of HOL Light, which would have required importing extra packages.</p>

<a name="185655886"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185655886" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185655886">Jason Rute (Jan 15 2020 at 00:17)</a>:</h4>
<blockquote>
<p>The response to any apply tactic request should already include the pretty printed version of the terms </p>
</blockquote>
<p>I didn’t see this behavior in <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">my notebook</a>.  All the apply tactic calls only return the full s-expressions.  For example see cell 10.</p>

<a name="185746134"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185746134" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185746134">Patrick Massot (Jan 15 2020 at 21:28)</a>:</h4>
<p><span class="user-mention" data-user-id="110026">@Simon Hudon</span> are you following this thread in order to see how the Lean4 editor integration could also be a machine learning rig integration? Or is it something completely different?</p>

<a name="185746790"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185746790" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185746790">Jesse Michael Han (Jan 15 2020 at 21:35)</a>:</h4>
<p>such integration would be more structured than the current language server protocol, which does not serialize the environment, nor fully elaborated terms (and only does so as unstructured strings via JSON)</p>

<a name="185746915"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185746915" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185746915">Simon Hudon (Jan 15 2020 at 21:36)</a>:</h4>
<p>The next language server will serialize the syntax tree and the type information</p>

<a name="185747146"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747146" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747146">Simon Hudon (Jan 15 2020 at 21:38)</a>:</h4>
<p><span class="user-mention" data-user-id="110031">@Patrick Massot</span>, does that answer your question? I'm not sure I understood what you were looking for</p>

<a name="185747174"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747174" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747174">Simon Cruanes (Jan 15 2020 at 21:39)</a>:</h4>
<p>So it'll still be bespoke and not LSP based?</p>

<a name="185747579"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747579" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747579">Patrick Massot (Jan 15 2020 at 21:43)</a>:</h4>
<blockquote>
<p>So it'll still be bespoke and not LSP based?</p>
</blockquote>
<p>We can add as many extension to LSP as we want.</p>

<a name="185747586"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747586" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747586">Simon Hudon (Jan 15 2020 at 21:43)</a>:</h4>
<p>We're basing it on LSP but we're going to get beyond the LSP basic features for the more advance uses</p>

<a name="185747611"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747611" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747611">Patrick Massot (Jan 15 2020 at 21:43)</a>:</h4>
<blockquote>
<p>Patrick Massot, does that answer your question? I'm not sure I understood what you were looking for</p>
</blockquote>
<p>I have no idea. I only hope people who followed this thread will know.</p>

<a name="185747612"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747612" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747612">Mario Carneiro (Jan 15 2020 at 21:43)</a>:</h4>
<p>I'm hoping you document those extensions</p>

<a name="185747736"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747736" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747736">Simon Cruanes (Jan 15 2020 at 21:45)</a>:</h4>
<blockquote>
<p>We can add as many extension to LSP as we want.</p>
</blockquote>
<p>yes, but LSP remains based on buffers and JSON, I'm not sure I see how you can carry ASTs on it efficiently?</p>

<a name="185747750"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747750" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747750">Mario Carneiro (Jan 15 2020 at 21:45)</a>:</h4>
<p>you can json anything</p>

<a name="185747804"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747804" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747804">Mario Carneiro (Jan 15 2020 at 21:46)</a>:</h4>
<p>I guess the efficiency isn't so great, but as long as it's only sent when needed it shouldn't be so bad</p>

<a name="185747855"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185747855" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185747855">Simon Cruanes (Jan 15 2020 at 21:46)</a>:</h4>
<p>sometimes I wish LSP had been built on msgpack-rpc or something like that</p>

<a name="185748765"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185748765" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185748765">Mario Carneiro (Jan 15 2020 at 21:58)</a>:</h4>
<p>huh, msgpack is pretty cool</p>

<a name="185749163"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/185749163" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#185749163">Simon Cruanes (Jan 15 2020 at 22:03)</a>:</h4>
<p>especially when you want to embed big chunks of code into it… no escaping needed</p>

<a name="186201897"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186201897" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186201897">Stanislas Polu (Jan 21 2020 at 16:46)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> and others friends knowledgeable about Holist. I've been able to spin up a holist instance using the <code>gcr.io/deepmath/hol-light</code> image. One thing that I expected from reading the code and introspecting the proof logs was that all theorems fingerprints appearing in the proof logs would be directly usable with that image but it looks like that's not the case. How does one is supposed to interact with the prover for a goal part of the test set? Do they have to replay and register all theorems first?</p>

<a name="186202542"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186202542" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186202542">Stanislas Polu (Jan 21 2020 at 16:53)</a>:</h4>
<p>Example code failing:</p>
<div class="codehilite"><pre><span></span>for_all_x_exists_y_x_equals_y = Theorem(
    name=&quot;FORALL_X_EXISTS_Y_SUCH_THAT_X_EQUALS_Y&quot;,
    conclusion=&quot;(a (c (fun (fun A (bool)) (bool)) !) (l (v A x) (a (c (fun (fun A (bool)) (bool)) ?) (l (v A y) (a (a (c (fun A (fun A (bool))) =) (v A x)) (v A y))))))&quot;,
    training_split=Theorem.Split.TESTING,
    tag=Theorem.Tag.THEOREM,
)

if __name__ == &#39;__main__&#39;:
    with grpc.insecure_channel(&#39;10.72.7.138:2000&#39;) as channel:
        stub = ProofAssistantServiceStub(channel)

        request3 = ApplyTacticRequest(goal=for_all_x_exists_y_x_equals_y, tactic=&quot;SIMP_TAC [ THM 220805353555668225 ]&quot;)
        print(&quot;Request:&quot;)
        print(request3)

        response3 = stub.ApplyTactic(request3)
        print(&quot;Response:&quot;)
        print(response3)
</pre></div>


<p>Where <code>220805353555668225</code> is the fingerprint of a theorem argument taken from the training set (appears in <code>human/train/prooflogs-00037-of-00600.pbtxt</code>)</p>
<p>This gives:</p>
<div class="codehilite"><pre><span></span>Request:
goal {
  conclusion: &quot;(a (c (fun (fun A (bool)) (bool)) !) (l (v A x) (a (c (fun (fun A (bool)) (bool)) ?) (l (v A y) (a (a (c (fun A (fun A (bool))) =) (v A x)) (v A y))))))&quot;
  tag: THEOREM
  name: &quot;FORALL_X_EXISTS_Y_SUCH_THAT_X_EQUALS_Y&quot;
  training_split: TESTING
}
tactic: &quot;SIMP_TAC [ THM 220805353555668225 ]&quot;

Response:
error: &quot;Failure(\&quot;No theorem exists with index 220805353555668225\&quot;)&quot;
</pre></div>

<a name="186202862"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186202862" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186202862">Stanislas Polu (Jan 21 2020 at 16:56)</a>:</h4>
<p>Or in other words how can I easily replay a proof log ?</p>

<a name="186203965"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186203965" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186203965">Stanislas Polu (Jan 21 2020 at 17:06)</a>:</h4>
<p>Ah I now realize that some theorems in <code>theorem_database_v1.1.textpb</code> are registered and usable.  I think only definitions are registered, but other theorems are not. </p>
<p>The question therefore remains?</p>

<a name="186210355"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186210355" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186210355">Jason Rute (Jan 21 2020 at 18:10)</a>:</h4>
<p>I was under the impression, possibly wrong, that one needs to replay (VerifyProof) and register (RegisterTheorem) all the theorems.  Of course this is assuming you are working in the “low level” gRPC API.  If you are working in the “high level” Python API then I assume the Python code does that stuff for you, but I haven’t explored that as much yet.</p>

<a name="186211833"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186211833" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186211833">Stanislas Polu (Jan 21 2020 at 18:27)</a>:</h4>
<p>Maybe <span class="user-mention" data-user-id="217806">@Markus Rabe</span> or <span class="user-mention" data-user-id="239426">@Christian Szegedy</span> can shed some light on this? <span aria-label="grimacing" class="emoji emoji-1f62c" role="img" title="grimacing">:grimacing:</span></p>

<a name="186218006"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186218006" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186218006">Christian Szegedy (Jan 21 2020 at 19:31)</a>:</h4>
<blockquote>
<blockquote>
<p>The response to any apply tactic request should already include the pretty printed version of the terms </p>
</blockquote>
<p>I didn’t see this behavior in <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">my notebook</a>.  All the apply tactic calls only return the full s-expressions.  For example see cell 10.</p>
</blockquote>
<p>It looks like (unfortunately) that this is only in our Google-internal version. We could do another round of exporting, especially that we have some code for an ICLR paper that should be open-sourced as well.</p>

<a name="186218426"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186218426" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186218426">Christian Szegedy (Jan 21 2020 at 19:35)</a>:</h4>
<blockquote>
<p>I was under the impression, possibly wrong, that one needs to replay (VerifyProof) and register (RegisterTheorem) all the theorems.  Of course this is assuming you are working in the “low level” gRPC API.  If you are working in the “high level” Python API then I assume the Python code does that stuff for you, but I haven’t explored that as much yet.</p>
</blockquote>
<p>The current verifier verifies theorems in their original context. So currently. you need to replay the whole theorem library in order to verify any number of theorems:<br>
- You can verify only theorems that came from the HOL-Light library (complex),<br>
- You can verify any number of theorems (you don't need to verify all of them)<br>
- All the theorems in the library will be run through the kernel for verification.<br>
- Those theorems that had an external proof (to be verified) will use their external proof at exactly that position where the theorem was proved originally.</p>

<a name="186220118"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186220118" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186220118">Christian Szegedy (Jan 21 2020 at 19:52)</a>:</h4>
<blockquote>
<p>Ah I now realize that some theorems in <code>theorem_database_v1.1.textpb</code> are registered and usable.  I think only definitions are registered, but other theorems are not. </p>
<p>The question therefore remains?</p>
</blockquote>
<p>The human prooflogs contain proof-steps that rely on theorems created "on the fly" by forward reasoning steps (so called conversions). These theorems don't show up in the theorem database. Also proofs relying on them can't be replayed as conversions can't be replayed either.</p>
<p>On the other hand the exported tensorflow examples contain the actual s-expression of those parameters, so if somebody uses those examples, the corresponding theorem can be used for training the parameter-selection models, even if those tactic-parameters don't show up in the proof-logs.</p>
<p>Around 60% of the human proofs can be replayed, as a large number of them uses theorems deduced by forward reasoning steps, other theorems use ad-hoc substitution of terms that we did not log either.</p>

<a name="186252165"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186252165" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186252165">Markus Rabe (Jan 22 2020 at 03:20)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> <span class="user-mention" data-user-id="115715">@Jason Rute</span><br>
The example above failed because the theorem with the fingerprint (or "index") 220805353555668225 is unknown to HOL Light when it is started up. Only the "core" Theorems are loaded at that point (which includes some basic definitions and theorems). Before you use any other theorem you need to register that theorem with the RegisterTheoremRequest.</p>
<p>As Christian said, don't expect all human-written proofs to go through, as some tactics are not supported and not all theorems that humans used in the proofs are in our theorem database.</p>
<p>As a final note: VerifyProof was only used for a deprecated version of our proof checker. Currently it is not used for anything and should be ignored.</p>

<a name="186268156"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186268156" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186268156">Stanislas Polu (Jan 22 2020 at 09:18)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> Thanks! Let me experiment with that. Ack re the obvious non-possibility to input any human proof. That being said, is it true that we can proof check all the proofs in the proof logs?</p>

<a name="186268720"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186268720" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186268720">Stanislas Polu (Jan 22 2020 at 09:26)</a>:</h4>
<p>Ah from reading <span class="user-mention" data-user-id="239426">@Christian Szegedy</span> post above I realize that property (replayability of the proof logs) does not hold true. If only 60% of the human proofs can be replayed, then 60% is somewhat of an upper bound on the performance of any supervised prover, right? (not sure it's mentioned in the papers?)</p>

<a name="186269417"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186269417" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186269417">Stanislas Polu (Jan 22 2020 at 09:35)</a>:</h4>
<blockquote>
<p>On the other hand the exported tensorflow examples contain the actual s-expression of those parameters, so if somebody uses those examples, the corresponding theorem can be used for training the parameter-selection models, even if those tactic-parameters don't show up in the proof-logs.</p>
</blockquote>
<p>I was under the impression that the information contained in the proof logs (pbtxt) was equivalent to the information contained in the tf examples (for the positive arguments) ? Is it not true? Is there a source of truth for the specification of the content of these files?</p>

<a name="186269695"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186269695" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186269695">Stanislas Polu (Jan 22 2020 at 09:39)</a>:</h4>
<p>Finally <span class="user-mention" data-user-id="217806">@Markus Rabe</span> is your latest comment on VerifyProof true of the publicly available version? (Thanks thanks!)</p>

<a name="186272422"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186272422" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186272422">Jason Rute (Jan 22 2020 at 10:14)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> I’m under the impression from my experiments with the public HOList Docker image that one has to first verify a theorem before one can register it (and it has to be the most recently verified theorem).  I assume this has gone away in the internal versions.</p>

<a name="186272506"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186272506" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186272506">Jason Rute (Jan 22 2020 at 10:15)</a>:</h4>
<p>Also, I assume the way that RegisterTheorem now works is to add the theorem as an axiom using the CHEAT tactic?</p>

<a name="186278286"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186278286" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186278286">Stanislas Polu (Jan 22 2020 at 11:39)</a>:</h4>
<p>Form the code in [0], it looks like anything received from RegisterTheorem is indeed assumed:</p>
<div class="codehilite"><pre><span></span>Theorem_fingerprint.index_thm index (Drule.mk_thm (to_term_list gs));
</pre></div>


<p>As Drule.mk_thm is a wrapper around the ASSUME tactic I believe.</p>
<p>But unclear if [0] is what is deployed in the <code>gcr.io/deepmath/hol-light</code> image?</p>
<p>[0] <a href="https://github.com/brain-research/hol-light/blob/master/sandboxee.ml#L141-L144" target="_blank" title="https://github.com/brain-research/hol-light/blob/master/sandboxee.ml#L141-L144">https://github.com/brain-research/hol-light/blob/master/sandboxee.ml#L141-L144</a></p>

<a name="186305426"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186305426" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186305426">Stanislas Polu (Jan 22 2020 at 16:46)</a>:</h4>
<p>I confirm that you can register any theorem (Only caveat is that it seems that the fingerprint does not get returned if not passed).</p>

<a name="186305605"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186305605" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186305605">Stanislas Polu (Jan 22 2020 at 16:48)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> can you expand on the limitation related to conversions? Replaying the prooflogs would just fail there? From skimming through the <a href="http://parse_tactic.ml" target="_blank" title="http://parse_tactic.ml">parse_tactic.ml</a> code it looks like there is some support for conversions? What are the current limitations?</p>

<a name="186329092"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186329092" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186329092">Christian Szegedy (Jan 22 2020 at 20:45)</a>:</h4>
<blockquote>
<p>If only 60% of the human proofs can be replayed, then 60% is somewhat of an upper bound on the performance of any supervised prover, right? (not sure it's mentioned in the papers?)</p>
</blockquote>
<p>This is not necessarily true. Since we use the network to guide a search, if the search explores enough branches it can discover proofs that are alternative to the human proofs.</p>

<a name="186329489"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186329489" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186329489">Christian Szegedy (Jan 22 2020 at 20:50)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239426">Christian Szegedy</span> can you expand on the limitation related to conversions? Replaying the prooflogs would just fail there? From skimming through the <a href="http://parse_tactic.ml" target="_blank" title="http://parse_tactic.ml">parse_tactic.ml</a> code it looks like there is some support for conversions? What are the current limitations?</p>
</blockquote>
<p>We log some of the conversions, but the ApplyTactic function call can't make use of them.</p>
<p>We have a new internal extension to the API that allows the application of "rules" (forward reasoning steps), we have run some preliminary expriments using them, but we don't have a proper integration, especially proof replay and verification are not implemented for them. We plan to open source our extensions to the interface as soon as there is enough interest in the community to use it.</p>

<a name="186330963"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186330963" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186330963">Christian Szegedy (Jan 22 2020 at 21:06)</a>:</h4>
<p>BTW, this is the code to properly initialize the environment with all of the (complex) proofs:</p>
<p><a href="https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359" target="_blank" title="https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359">https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359</a></p>

<a name="186332996"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186332996" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186332996">Markus Rabe (Jan 22 2020 at 21:30)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> You're right. The publicly available version of our modified HOL Light still includes the old proof checker. It should still work. <br>
What I meant is that we have a new proof checker that bypasses the API and instead compiles proof logs to OCaml code. Thereby we don't have to trust our Python code and the API. The new proof checker is described at <a href="http://deephol.org" target="_blank" title="http://deephol.org">deephol.org</a>.</p>

<a name="186333304"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186333304" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186333304">Markus Rabe (Jan 22 2020 at 21:33)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> <span class="user-mention" data-user-id="249373">@Stanislas Polu</span> Indeed, you can even register terms that are not true. So it is your responsibility to stay sound in the stateless API. (Hence our stand-alone proof checker.)</p>

<a name="186366816"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186366816" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186366816">Stanislas Polu (Jan 23 2020 at 08:18)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span>  Thanks for your additional comments</p>

<a name="186366828"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186366828" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186366828">Stanislas Polu (Jan 23 2020 at 08:18)</a>:</h4>
<blockquote>
<p>BTW, this is the code to properly initialize the environment with all of the (complex) proofs:<br>
<a href="https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359" target="_blank" title="https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359">https://github.com/tensorflow/deepmath/blob/c51df033cdf8d2d103fd277beb3b9acf39b8d9c1/deepmath/deephol/prover.py#L359</a></p>
</blockquote>
<p>I had stumbled on this and was plan to use exactly that <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span></p>
<blockquote>
<p>We have a new internal extension to the API that allows the application of "rules" (forward reasoning steps), we have run some preliminary expriments using them, but we don't have a proper integration, especially proof replay and verification are not implemented for them. We plan to open source our extensions to the interface as soon as there is enough interest in the community to use it.</p>
</blockquote>
<p>There is interest to use it :)</p>

<a name="186366915"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186366915" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186366915">Stanislas Polu (Jan 23 2020 at 08:20)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> thanks!</p>

<a name="186367435"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186367435" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186367435">Stanislas Polu (Jan 23 2020 at 08:30)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> Let me rephrase a bit what you stated. Even without support for forward reasoning with conversions one could imagine that a system that takes the results of the conversion (input to later tactics) as part of its training set, it could potentially replay some theorems successfully skipping entirely the conv step. Do you guys include these theorems to your database when training?</p>

<a name="186409482"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186409482" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186409482">Christian Szegedy (Jan 23 2020 at 16:56)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> If you mean by "replay" proving the theorem in a different way, then yes. It happens a lot. Actually, machine generated proofs tend to be quite different from human proofs, even if premise selection was trained by imitation only. Also logging (and training on) "theorems" (or true statements) produced by the conversions is still useful for training the models that decides which tactic parameters are the most useful, even if the prover process cannot do conversions. That's what we do.</p>
<p>Also, thanks for the feedback, we will discuss how to update the github repo with the API extensions with minimum effort. The problem is that our internal version diverged so much from the open source that it makes it hard for us to easily submit the changes, but we will look into that.</p>

<a name="186421586"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186421586" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186421586">Stanislas Polu (Jan 23 2020 at 18:52)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> thanks!</p>

<a name="186476176"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186476176" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186476176">Stanislas Polu (Jan 24 2020 at 09:43)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> I'm a bit surprised by the following:</p>
<div class="codehilite"><pre><span></span>root@dev-1-0:~# du -h ~/deephol-data/deepmath/deephol/proofs/human/test
3.3G    /root/deephol-data/deepmath/deephol/proofs/human/test
root@dev-1-0:~# du -h ~/deephol-data/deepmath/deephol/proofs/human/valid
2.4G    /root/deephol-data/deepmath/deephol/proofs/human/valid
root@dev-1-0:~# du -h ~/deephol-data/deepmath/deephol/proofs/human/train
9.2G    /root/deephol-data/deepmath/deephol/proofs/human/train
</pre></div>


<p>vs</p>
<div class="codehilite"><pre><span></span>root@dev-1-0:~# grep &quot;TEST&quot; ~/deephol-data/deepmath/deephol/theorem_database_v1.1.textpb | wc -l
14141
root@dev-1-0:~# grep &quot;VALIDATION&quot; ~/deephol-data/deepmath/deephol/theorem_database_v1.1.textpb | wc -l
3668
root@dev-1-0:~# grep &quot;TRAINING&quot; ~/deephol-data/deepmath/deephol/theorem_database_v1.1.textpb | wc -l
11655
</pre></div>


<p>Which gives a bytes/theorem (approximation) of:</p>
<div class="codehilite"><pre><span></span>TEST: ~233k
VALIDATION: ~654k
TRAIN: ~789k
</pre></div>


<p>Which indicates that the size of the proofs in the test set are noticeably smaller vs train/validation? Is that intentional? (or maybe a discrepancy in tf records for the test set?)</p>

<a name="186487969"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186487969" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186487969">Stanislas Polu (Jan 24 2020 at 12:46)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> sorry another quick question. It looks like <code>LABEL_TAC</code> is not accepted by the proof assistant. Any reason why they appear in the proof logs?</p>

<a name="186491122"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186491122" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186491122">Stanislas Polu (Jan 24 2020 at 13:25)</a>:</h4>
<p>FInally, while attempting to replay the proof logs with the following procedure: for all tactics taking a theorem argument, call RegisterTheorem on each argument and then for all tactics, call ApplyTactic.</p>
<p>I often, despite a successful call to RegisterTheorem (the fingerprint I use (the one from the proof logs) is returned to me with no error), I get an eventual error when applying the tactic with message "No theorem exists with index XXX". From reading the ML code, I have a hard time seeing how the fingerprint can be returned successfully at RegisterTheorem and then not being hitting that message meaning that the index does not has that fingerprint.</p>
<p>Example logs:</p>
<div class="codehilite"><pre><span></span>Replaying /Users/spolu/deephol-data/deepmath/deephol/proofs/human/test/prooflogs-00218-of-00537.jsonl
&gt; ApplyTactic X_GEN_TAC `(v (fun (cart (real) N) (bool)) s)`
&lt; ApplyTactic 1 goals
&gt; ApplyTactic X_GEN_TAC `(v (fun (cart (real) N) (bool)) t)`
&lt; ApplyTactic 1 goals
&gt; ApplyTactic DISCH_TAC
&lt; ApplyTactic 1 goals
&gt; ApplyTactic RAW_POP_TAC 0
&lt; ApplyTactic 1 goals
&gt; RegisterTheorem 3261843337692443473
&lt; RegisterTheorem 3261843337692443473
&gt; ApplyTactic REWRITE_TAC [ THM 3261843337692443473 ]
&lt; ApplyTactic 1 goals
&gt; RegisterTheorem 3276577123099513888
&lt; RegisterTheorem 3276577123099513888
&gt; ApplyTactic MP_TAC THM 3276577123099513888
!!! Failure(&quot;No theorem exists with index 3276577123099513888&quot;)
&gt; RegisterTheorem 3550116108290505704
&lt; RegisterTheorem 3550116108290505704
&gt; RegisterTheorem 1457252911920550478
&lt; RegisterTheorem 1457252911920550478
&gt; RegisterTheorem 4032148915606337071
&lt; RegisterTheorem 4032148915606337071
&gt; RegisterTheorem 1358160238249633387
&lt; RegisterTheorem 1358160238249633387
&gt; RegisterTheorem 34540287283234494
&lt; RegisterTheorem 34540287283234494
&gt; RegisterTheorem 3806712188414811372
&lt; RegisterTheorem 3806712188414811372
&gt; ApplyTactic SIMP_TAC [ THM 3550116108290505704 ; THM 1457252911920550478 ; THM 4032148915606337071 ; THM 1358160238249633387 ; THM 34540287283234494 ; THM 3806712188414811372 ]
!!! Failure(&quot;No theorem exists with index 34540287283234494&quot;)
&gt; ApplyTactic DISCH_TAC
&lt; ApplyTactic 1 goals
&gt; ApplyTactic RAW_POP_TAC 0
&lt; ApplyTactic 1 goals
&gt; RegisterTheorem 4441231563045595206
&lt; RegisterTheorem 4441231563045595206
&gt; ApplyTactic MP_TAC THM 4441231563045595206
!!! Failure(&quot;No theorem exists with index 4441231563045595206&quot;)
&gt; ApplyTactic ANTS_TAC
&lt; ApplyTactic 2 goals
&gt; RegisterTheorem 647530560333096154
&lt; RegisterTheorem 647530560333096154
&gt; ApplyTactic REWRITE_TAC [ THM 647530560333096154 ]
&lt; ApplyTactic 1 goals
</pre></div>


<p>As you can see this happens quite often.<br>
cc <span class="user-mention" data-user-id="217806">@Markus Rabe</span> <span class="user-mention" data-user-id="239426">@Christian Szegedy</span></p>

<a name="186491176"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186491176" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186491176">Stanislas Polu (Jan 24 2020 at 13:26)</a>:</h4>
<p>(sorry for all the questions, hope it'll be useful to the community)</p>

<a name="186495853"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186495853" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186495853">Stanislas Polu (Jan 24 2020 at 14:22)</a>:</h4>
<p>I believe I found what is going on from inspecting the logs of the container. It seems that the fingerprint mismatch. Unfortunately the "api" does not return the newly computed fingerprint but only the fingerprint passer as argument, but does use the new fingerprint for indexing. This is a bit unfortunate.</p>

<a name="186495865"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186495865" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186495865">Stanislas Polu (Jan 24 2020 at 14:22)</a>:</h4>
<p>(I'll explore as to why there are discrepancies in fingerprints)</p>

<a name="186498505"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186498505" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186498505">Stanislas Polu (Jan 24 2020 at 14:54)</a>:</h4>
<p>Problem solved on my end by fixing discrepancies in the S-Expr I was sending (escaped characters were not handled properly). Replaying logs seems to work properly now \o/ Hope this is all useful to others.</p>

<a name="186506019"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186506019" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186506019">Stanislas Polu (Jan 24 2020 at 16:13)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> in your walkthrough[0], the TRANS_TAC marshalling is a bit wrong. It takes a theorem then a term.<br>
[0] <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb</a></p>

<a name="186507286"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186507286" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186507286">Markus Rabe (Jan 24 2020 at 16:27)</a>:</h4>
<p>All good questions. Note that the theorem database also includes the flyspeck corpus, but I believe we have not published the proof logs for flyspeck. I believe the flyspeck theorems are all labeled as TESTING. Hence your divisor is off for testing. If you want to be even more precise you should also discount the definitions, as they do not have proofs.</p>
<p>But still interesting that the size of the training for TESTING is significantly larger than for VALIDATION. I wasn't aware of that.</p>

<a name="186507358"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186507358" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186507358">Markus Rabe (Jan 24 2020 at 16:28)</a>:</h4>
<p>LABEL_TAC and other unsupported tactics are in the proof logs as we log the proofs as the humans wrote them.</p>

<a name="186507925"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186507925" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186507925">Markus Rabe (Jan 24 2020 at 16:34)</a>:</h4>
<p>As for the failures of RegisterTheorem: Yes, the fingerprint is unfortunately not the one computed in HOL Light, but just the one that you indicated in the register theorem request. We're fixing this internally as well, so any future releases should not have the problem. Thanks for noticing and for all the work you've put in!</p>

<a name="186523943"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186523943" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186523943">Stanislas Polu (Jan 24 2020 at 19:15)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> thanks a lot for all your help. One quite orthogonal question, what is the rationale for the current API (somewhat constrained in term of tactics available) vs directly interacting with a live hol light goal stack (which would accept pretty much anything)?</p>

<a name="186597371"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186597371" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186597371">Markus Rabe (Jan 26 2020 at 01:38)</a>:</h4>
<p>Several reasons afaik: we need a stateless API, and we wanted to communicate via proto messages to abstract from the fact that we use HOL Light and to have flexibility in the deployment of the provers.</p>

<a name="186719316"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186719316" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186719316">Stanislas Polu (Jan 27 2020 at 19:58)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> the original Holist paper[0] states that final results should be shared using the test set (4.2) but it looks like the main result is produced on the validation set (Table 2) and there is no such result for the test set? I believe it is the same for the SoTa paper [1]. Am I missing something?<br>
[0] <a href="https://arxiv.org/pdf/1904.03241.pdf" target="_blank" title="https://arxiv.org/pdf/1904.03241.pdf">https://arxiv.org/pdf/1904.03241.pdf</a><br>
[1] <a href="https://arxiv.org/pdf/1905.10006.pdf" target="_blank" title="https://arxiv.org/pdf/1905.10006.pdf">https://arxiv.org/pdf/1905.10006.pdf</a></p>

<a name="186719383"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186719383" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186719383">Stanislas Polu (Jan 27 2020 at 19:59)</a>:</h4>
<p><span class="user-mention" data-user-id="217806">@Markus Rabe</span> Thanks. Arguably you could have created a new GoalStack for each request and have full support of the Tactics? Is there a reason why you didn't go for that?</p>

<a name="186719764"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186719764" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186719764">Stanislas Polu (Jan 27 2020 at 20:03)</a>:</h4>
<p>Finally, the last set of errors I'm getting when "replaying" the validation set are related to CONV tactics (which I believe are expected since I can see in the ML code that the CONV passed to CONV_TAC are not supported), example:</p>
<div class="codehilite"><pre><span></span>&gt; ApplyTactic CONV_TAC REAL_FIELD
!!! Failure(&quot;Parse failure at :9: expected conv but found REAL_FIELD&quot;)
--
&gt; ApplyTactic CONV_TAC COND_ELIM_CONV
!!! Failure(&quot;Parse failure at :9: expected conv but found COND_ELIM_CONV&quot;)
</pre></div>


<p>I also have a few errors that seem to be due to an erroneous tracing, example:</p>
<div class="codehilite"><pre><span></span>&gt; ApplyTactic X_CHOOSE_TAC `(v (cart (real) N) y)` THM 1452504403316335102
!!! Failure(&quot;X_CHOOSE_TAC: expected type :real^M but got :real^N&quot;)
</pre></div>


<p>Are you guys aware of those ^</p>
<p>Finally, the identify is sometime passed to the GEN_WRITE_TAC as <code>I</code> but it does not seem supported, is that expected?</p>
<div class="codehilite"><pre><span></span>&gt; ApplyTactic GEN_REWRITE_TAC I [ THM 2993471090521929300 ]
!!! Failure(&quot;Parse failure at :16: expected convfn but found I&quot;)
</pre></div>

<a name="186741900"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186741900" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186741900">Christian Szegedy (Jan 28 2020 at 00:37)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239426">Christian Szegedy</span> the original Holist paper[0] states that final results should be shared using the test set (4.2) but it looks like the main result is produced on the validation set (Table 2) and there is no such result for the test set? I believe it is the same for the SoTa paper [1]. Am I missing something?</p>
</blockquote>
<p>Yes, I think it is sloppiness on our side. We have verified our results internally with the test set and the results were very close. Also, we got pretty decent results on the Flyspeck corpus which is a completely independent branch from the training set. This is also reported in the HOList paper.</p>
<p>We will rerun our model from the GNN paper with the test set and update the paper. I am quite confident that the results don't change significantly to the validation set as we did not do a lot of tuning on it.</p>

<a name="186742113"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186742113" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186742113">Christian Szegedy (Jan 28 2020 at 00:40)</a>:</h4>
<blockquote>
<p>Finally, the last set of errors I'm getting when "replaying" the validation set are related to CONV tactics (which I believe are expected since I can see in the ML code that the CONV passed to CONV_TAC are not supported), example:</p>
</blockquote>
<p>All those errors are expected. Currently the API supports only theorem parameters and only the selected set of 42 tactics we have enabled.</p>

<a name="186750599"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186750599" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186750599">Christian Szegedy (Jan 28 2020 at 03:40)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239426">Christian Szegedy</span> the original Holist paper[0] states that final results should be shared using the test set (4.2) but it looks like the main result is produced on the validation set (Table 2) and there is no such result for the test set? I believe it is the same for the SoTa paper [1]. Am I missing something?<br>
[0] <a href="https://arxiv.org/pdf/1904.03241.pdf" target="_blank" title="https://arxiv.org/pdf/1904.03241.pdf">https://arxiv.org/pdf/1904.03241.pdf</a><br>
[1] <a href="https://arxiv.org/pdf/1905.10006.pdf" target="_blank" title="https://arxiv.org/pdf/1905.10006.pdf">https://arxiv.org/pdf/1905.10006.pdf</a></p>
</blockquote>
<p>Sarah has rerun the model from the GNN paper for the validation and training set and verified the validation set performance at 49.98% (we proved 1 theorem less with the current code , which is in noise range), the test set performance is 46.89% (1493 theorem proved out of 3184). We will update the paper accordingly. We don't think that the 2% gap is the result of overfitting, since during the test set construction, we needed to deduplicate some simple theorems  that occurred in the validation and test sets and ended up in the validation set.</p>
<p>Accordingly, the (open sourced) "Deeper WaveNet" model proves 30.1% of the test set .</p>
<p>Thanks a lot for constructive suggestion!</p>

<a name="186760332"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186760332" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186760332">Stanislas Polu (Jan 28 2020 at 08:01)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> thanks for the quick answer (and thanks to <span class="user-mention" data-user-id="239408">@Sarah Loos</span> et al for re-running the model on the test set \o/)</p>

<a name="186777567"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186777567" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186777567">Stanislas Polu (Jan 28 2020 at 12:28)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> (sorry for the continuous stream of questions) using <code>theorem_database_v1.1.textpb</code> I get the following counts, filtering out <code>"flyspeck" in library_tag</code> and considering only <code>tag=THEOREM</code>:</p>
<div class="codehilite"><pre><span></span>    3618 test_benchmark
   11654 train_benchmark
    3666 validation_benchmark
</pre></div>


<p>Any idea where is the discrepancy with the number you report above (3184 theorems for the test set) coming from?</p>

<a name="186778038"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186778038" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186778038">Stanislas Polu (Jan 28 2020 at 12:35)</a>:</h4>
<blockquote>
<p>All those errors are expected. Currently the API supports only theorem parameters and only the selected set of 42 tactics we have enabled.</p>
</blockquote>
<p>Just wanted to note that the (hol-light fork) grpc API do support <code>term</code> parameters as well as a selection of <code>convfn</code> parameters, but not all of them</p>

<a name="186782109"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186782109" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186782109">Sarah Loos (Jan 28 2020 at 13:30)</a>:</h4>
<p>There are library tags that split core, complex, and flyspeck. The counts you give are for core+complex. However, we need to prove core before our 41 tactics are defined, so proving them again using those 41 tactics could allow circular proofs.  We train on complex + core, but we validate and test on complex alone. That leaves 3225 theorems in validation, and 3184 in test (fewer in test due to the deduplication Christian already mentioned.</p>

<a name="186802045"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/186802045" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#186802045">Stanislas Polu (Jan 28 2020 at 16:55)</a>:</h4>
<p>Thanks <span class="user-mention" data-user-id="239408">@Sarah Loos</span> that perfectly answers my question!</p>

<a name="187261298"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187261298" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187261298">Stanislas Polu (Feb 03 2020 at 13:26)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> <span class="user-mention" data-user-id="239426">@Christian Szegedy</span> could you shed some light on the nature of the theorems used as arguments of tactics in the proof logs but that are never proved in the proof logs and do not appear in the theorem database. A good number of such theorems appear to be simple REFL forms <code>t |- t</code> but that's not always true. A couple examples that are never proved and do not appear as immediately trivial (there are number of those):</p>
<div class="codehilite"><pre><span></span>- 1922886628595100084 used in [&quot;1040308614564293951&quot;, &quot;1068224724366208851&quot;, &quot;1112690888686785731&quot;, &quot;1158014677968443900&quot;, &quot;1164501139575860811&quot;, &quot;130472234907213660&quot;, &quot;1343784825924590900&quot;, &quot;1352911036261694414&quot;, &quot;1418978342581894759&quot;, &quot;1474549535369966656&quot;, &quot;1513888587157156538&quot;, &quot;1572453226266457388&quot;, &quot;1599750970754608282&quot;, &quot;1620034501266471566&quot;, &quot;1769559777913546939&quot;, &quot;205743562540180251&quot;, &quot;2109293764129290517&quot;, &quot;2126361288542869040&quot;, &quot;2277895992876250526&quot;, &quot;2293215433400331757&quot;, &quot;256901751634745145&quot;, &quot;2607920021777763754&quot;, &quot;2756227240911330037&quot;, &quot;2814672109419638476&quot;, &quot;2870558538778029314&quot;, &quot;288796831567879679&quot;, &quot;2926604530781841183&quot;, &quot;294378225568766821&quot;, &quot;2962920115237185377&quot;, &quot;3005304601846519849&quot;, &quot;3017833332354727747&quot;, &quot;3073340668359178974&quot;, &quot;3259640035187228089&quot;, &quot;3295559022993975824&quot;, &quot;3336700799157016006&quot;, &quot;3392958071979927571&quot;, &quot;3417040980091477675&quot;, &quot;3481134151910663053&quot;, &quot;3506191389615981736&quot;, &quot;3604528285204124469&quot;, &quot;360880980515827351&quot;, &quot;3644717466658263822&quot;, &quot;3704608103438291317&quot;, &quot;3714364479833122652&quot;, &quot;3723658874948739190&quot;, &quot;3853086673632578265&quot;, &quot;3886915657877240313&quot;, &quot;3984011009279567911&quot;, &quot;4143882562872306321&quot;, &quot;4166654576449910877&quot;, &quot;4215257151813055174&quot;, &quot;4327049118031780666&quot;, &quot;438205370349448367&quot;, &quot;4527762605576935742&quot;, &quot;4571588623963401944&quot;, &quot;4588263066752175426&quot;, &quot;552208215923821302&quot;, &quot;744097452034251800&quot;, &quot;799704810144038539&quot;, &quot;849058353815678716&quot;, &quot;955717506610167167&quot;, &quot;976594976798091141&quot;]
- 1557372991274822741 used in [&#39;1710726984666665793&#39;, &#39;1775991960234953438&#39;, &#39;2674137462841098894&#39;, &#39;2814672109419638476&#39;, &#39;3261843337692443473&#39;, &#39;3365009944937700598&#39;, &#39;352808503728591300&#39;, &#39;3780566399882342374&#39;, &#39;3836286049713174388&#39;, &#39;3949756777445235777&#39;, &#39;527345757246532498&#39;, &#39;695832356799713264&#39;, &#39;709680727040550934&#39;]
- 3887972958511973677 used in [&#39;1671664489604345755&#39;, &#39;2044835932020195874&#39;]
</pre></div>


<p>In particular, since they appear in proof logs as valid premises, do you consider valid the use of these theorems by a prover against your benchmark?</p>

<a name="187263434"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187263434" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187263434">Stanislas Polu (Feb 03 2020 at 13:53)</a>:</h4>
<p>(and if so) under which ordering constraints.</p>

<a name="187274148"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187274148" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187274148">Stanislas Polu (Feb 03 2020 at 15:50)</a>:</h4>
<p>After further exploration I can see 86747 such unproven but used theorems across train/test/valid of which 56726 are trivial "REFLs" (which are therefore trivially provable), but it's harder to characterize clearly the 30k others.</p>

<a name="187296782"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187296782" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187296782">Sarah Loos (Feb 03 2020 at 19:48)</a>:</h4>
<p>There is a difference between the human proofs that we have logged and the synthetic proofs.  </p>
<p>From your description, I believe you're looking at the human proofs.  We only recorded backward tactics (loosely speaking, steps of type tactic in HOL Light, which convert a goal to a new goalstate).  We did not implement logging for human theorems that are generated via forward steps (e.g. from rules that convert thm-&gt;thm in HOL Light, like SPECL).  Many human proofs are a combination of forward and backward proof steps.  In training, we keep these forward generated theorems as arguments, since they still have semantic meaning that is useful for training, but at present we would not be able to generate these exact proofs, since the forward-derived theorems are not available in our theorem database and we have not yet implemented forward proving steps.  This doesn't mean that the theorem can't be proved via DeepHOL, just that it may need to take more backward steps to close the goal. </p>
<p>Another place that these theorems can come from is the assumption list in the goal.  I believe around 45% of the theorem arguments in the human training steps come directly from the assumption list in the current goal.  These can come from either being explicitly passed as tactic arguments, or added in bulk via an ASM_* tactic.</p>
<p>Regarding the synthetic proofs, these arguments should all come from the theorem database as you expected.</p>

<a name="187298282"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187298282" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187298282">Stanislas Polu (Feb 03 2020 at 20:05)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> Thanks! Yes, talking about the human proofs.</p>
<p>So it would be rather unfair to add these theorems to the theorem database of the prover (they should rather be re-demonstrated (in some backward way) at proof time if needed) since they do carry the forward reasoning steps that produced them (however simple they are).</p>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> mentioned that you had an internal version that would extend support for forward reasoning / conversions, are the proof logs different in that next version how would that change the overall picture here?</p>

<a name="187299056"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187299056" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187299056">Stanislas Polu (Feb 03 2020 at 20:15)</a>:</h4>
<p>(from re-reading earlier posts, I presume it would allow to technically generate these theorems through forward reasoning steps, but your current system does not cover creating the associated proof logs. Aka you added a forward reasoning API to register new theorems through conversions, but the proof logs remain the same?)</p>

<a name="187299723"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187299723" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187299723">Christian Szegedy (Feb 03 2020 at 20:23)</a>:</h4>
<blockquote>
<p>A good number of such theorems appear to be simple REFL forms <code>t |- t</code> but that's not always true.</p>
</blockquote>
<p>Thanks a lot for the insight. BTW, we have part timer looking into adding the capability of applying REFLs or just enhancing the theorem database by equations in the other direction. We try to figure out the best way to go about it.</p>

<a name="187299905"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187299905" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187299905">Stanislas Polu (Feb 03 2020 at 20:25)</a>:</h4>
<blockquote>
<p>Another place that these theorems can come from is the assumption list in the goal. I believe around 45% of the theorem arguments in the human training steps come directly from the assumption list in the current goal. These can come from either being explicitly passed as tactic arguments, or added in bulk via an ASM_* tactic.</p>
</blockquote>
<p>I will verify how many land in that category, but probably less than 45% given the above?</p>

<a name="187300257"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187300257" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187300257">Stanislas Polu (Feb 03 2020 at 20:28)</a>:</h4>
<blockquote>
<p>Thanks a lot for the insight. BTW, we have part timer looking into adding the capability of applying REFLs or just enhancing the theorem database by equations in the other direction. We try to figure out the best way to go about it.</p>
</blockquote>
<p>The simplest cases (eg REFL) can easily be handled outside of the container; obviously with the associated decrease in trust in the proofs generated.</p>

<a name="187303840"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187303840" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187303840">Stanislas Polu (Feb 03 2020 at 21:04)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> out of curiosity do you have an example hol light theorem whose code picks an assumption argument without the use of an ASM_* tactic?</p>

<a name="187312402"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187312402" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187312402">Sarah Loos (Feb 03 2020 at 22:33)</a>:</h4>
<blockquote>
<blockquote>
<p>Another place that these theorems can come from is the assumption list in the goal. I believe around 45% of the theorem arguments in the human training steps come directly from the assumption list in the current goal. These can come from either being explicitly passed as tactic arguments, or added in bulk via an ASM_* tactic.</p>
</blockquote>
<p>I will verify how many land in that category, but probably less than 45% given the above?</p>
</blockquote>
<p>A clarification: the assumption list for a goal is a list of theorems.  In many cases, these theorems are of the form <code>t |- t</code>, so they look as if they could be generated via a forward call to REFL, but they could also come from the assumption list.  Here I am referring to the internal HOL Light representations - interactive HOL Light only displays the conclusion of each theorem in a goal's assumption list.  In our proof logging of the goals we were also only keeping the conclusions for brevity.</p>
<p>Unlike the synthetic proof logs, which serve as a proof witness that can be passed to HOL Light via the proof checker, the human proof logs were not generated to be proof witnesses, but rather to serve as a source of training data.  In many cases they have steps that we can't yet replicate (tactics that require term generation, forward theorem generation, etc.).  However, we wanted to release them as a reference - we haven't yet leveraged all the data that is recorded in the human proof logs, but other people might be able to!  I hope this clarifies their purpose a bit.</p>

<a name="187312990"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187312990" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187312990">Sarah Loos (Feb 03 2020 at 22:39)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239408">Sarah Loos</span> out of curiosity do you have an example hol light theorem whose code picks an assumption argument without the use of an ASM_* tactic?</p>
</blockquote>
<p>Unfortunately I don't know of any examples off hand that I could point you to.  Of course, you could search for one by looking for any tactic that has some but not all of the assumptions passed as theorem arguments, but I'm guessing you'd already thought of that. :)</p>

<a name="187391654"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187391654" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187391654">Stanislas Polu (Feb 04 2020 at 19:31)</a>:</h4>
<p>(simple ASSUME is the canonical way to turn an hypothesis into a tactic theorem argument)</p>

<a name="187393246"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187393246" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187393246">Stanislas Polu (Feb 04 2020 at 19:47)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> thanks for reiterating the purpose of the human vs synthetic proof logs. Very clear <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span></p>

<a name="187490923"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187490923" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187490923">Sarah Loos (Feb 05 2020 at 20:21)</a>:</h4>
<blockquote>
<p>(simple ASSUME is the canonical way to turn an hypothesis into a tactic theorem argument)</p>
</blockquote>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> Yes, this is how you'd implement ASM_* rules that are forward proofs on theorems.  However, it's slightly different for ASM_* tactics for backward proving on goals.  In the backward case, you should use the existing theorems in the goal assumption list (see ASM function <a href="https://github.com/jrh13/hol-light/blob/b913ffef1ffd16f64a81fe1b783f62e756d33a40/tactics.ml#L304" target="_blank" title="https://github.com/jrh13/hol-light/blob/b913ffef1ffd16f64a81fe1b783f62e756d33a40/tactics.ml#L304">here</a>).  If you use ASSUME, you'll actually be creating a new theorem.  The new theorem may often (or always, depending on your specific use case) be equivalent to the one in the goal assumption list, but not necessarily.  Not sure if the distinction is relevant for you, and feel free to disregard if not!</p>

<a name="187517473"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187517473" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187517473">Christian Szegedy (Feb 06 2020 at 03:32)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span></p>
<blockquote>
<p>(from re-reading earlier posts, I presume it would allow to technically generate these theorems through forward reasoning steps, but your current system does not cover creating the associated proof logs. Aka you added a forward reasoning API to register new theorems through conversions, but the proof logs remain the same?)</p>
</blockquote>
<p>Yes the Proof-Log and proof-checker will be extended. The modification to the proof-logs is relatively minor, though. The checker changes are more work, but will be essential.</p>

<a name="187535135"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187535135" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187535135">Stanislas Polu (Feb 06 2020 at 10:11)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> <span class="user-mention" data-user-id="239426">@Christian Szegedy</span> I was able to misuse holist (interacting with the <a href="http://gcr.io/deepmath/hol-light" target="_blank" title="http://gcr.io/deepmath/hol-light">gcr.io/deepmath/hol-light</a> container) to prove false using the RegisterTheorem / ApplyTacticRequest pair as documented in this thread. Could you explain how a user of holist should protect herself from this sequence of actions leading to a proof of false?</p>
<p><a href="https://gist.github.com/spolu/a9672849a8a13469eb20de6553ff016e" target="_blank" title="https://gist.github.com/spolu/a9672849a8a13469eb20de6553ff016e">https://gist.github.com/spolu/a9672849a8a13469eb20de6553ff016e</a></p>
<p>The problem comes from the <code>SUBST1_TAC</code> returning an erroneous Goal, or failing to fail properly (the hypothesis of the theorem passed not being part of the goal's hypothesis). How are we supposed to handle this situation?</p>

<a name="187535605"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187535605" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187535605">Stanislas Polu (Feb 06 2020 at 10:19)</a>:</h4>
<p>cc <span class="user-mention" data-user-id="115715">@Jason Rute</span> if you can reproduce and let me know what you think ^ ?</p>

<a name="187543215"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187543215" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187543215">Jason Rute (Feb 06 2020 at 12:26)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> Interesting.  I can try to verify later.  Have to tried plugging this into HOL Light?  I assume the problem is that HOL Light returns the goal as <code>p=T |- T =&gt; q</code>, and then HOList ApplyTactic neglects to return the hypothesis.  Is that correct?</p>

<a name="187544829"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187544829" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187544829">Stanislas Polu (Feb 06 2020 at 12:50)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span>  As mentioned in the documentation, the tactic is invalid if the goal's assumption does not include the theorem passed as argument's assumptions:</p>
<div class="codehilite"><pre><span></span># let pth = ASSUME `p = T`;;
val pth : thm = p &lt;=&gt; T |- p &lt;=&gt; T
# g `p ==&gt; q`;;
Warning: Free variables in goal: p, q
val it : goalstack = 1 subgoal (1 total)

`p ==&gt; q`

# e(SUBST1_TAC pth);;
Exception: Failure &quot;VALID: Invalid tactic&quot;.
</pre></div>


<p>(which is slightly more worrying since it means that somewhere SUBST1_TAC, through the API executes where it should fail? it's not just an assumption not being returned)</p>
<p>For completeness/reference, a valid use of the tactic:</p>
<div class="codehilite"><pre><span></span># g `p = T ==&gt; (p ==&gt; q)`;;
Warning: Free variables in goal: p, q
val it : goalstack = 1 subgoal (1 total)

`(p &lt;=&gt; T) ==&gt; p ==&gt; q`

# e(DISCH_TAC);;
val it : goalstack = 1 subgoal (1 total)

  0 [`p &lt;=&gt; T`]

`p ==&gt; q`

# e(SUBST1_TAC pth);;
val it : goalstack = 1 subgoal (1 total)

  0 [`p &lt;=&gt; T`]

`T ==&gt; q`
</pre></div>

<a name="187565872"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187565872" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187565872">Sarah Loos (Feb 06 2020 at 16:53)</a>:</h4>
<p>Thanks for documenting and sharing this example!  I am surprised that the same "VALID: Invalid tactic" isn't returned by HOList.  Like Jason, I would have expected HOL Light to return the theorem <code>p=T |- T =&gt; q</code>, which we don't consider to be a valid proof of the original goal (<code>|- p =&gt; q</code>), since hypotheses are added mid-proof.</p>
<blockquote>
<p>Could you explain how a user of holist should protect herself from this sequence of actions leading to a proof of false?</p>
</blockquote>
<ol>
<li>We don't allow theorems with hypotheses in our premise set, but this is enforced purely by convention (i.e. there are none in our theorem database) and is not well documented anywhere.</li>
<li>We rely on the proof checker, which reruns the found proof tree in HOL Light and checks that the resulting theorem object has no hypotheses and the conclusion is alpha-equiv to the original goal term.  <span class="user-mention" data-user-id="217806">@Markus Rabe</span></li>
</ol>

<a name="187569205"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187569205" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187569205">Stanislas Polu (Feb 06 2020 at 17:27)</a>:</h4>
<blockquote>
<p>We don't allow theorems with hypotheses in our premise set, but this is enforced purely by convention (i.e. there are none in our theorem database) and is not well documented anywhere.</p>
</blockquote>
<p>This is a surprising restriction, especially since the human proof logs don't comply to it.</p>
<p>So is it fair to say that Holist is not usable today for anything other than <code>TACTIC + theorem arguments coming from the theorem database *only*</code>?</p>

<a name="187569343"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187569343" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187569343">Stanislas Polu (Feb 06 2020 at 17:29)</a>:</h4>
<blockquote>
<p>We rely on the proof checker, which reruns the found proof tree in HOL Light and checks that the resulting theorem object has no hypotheses and the conclusion is alpha-equiv to the original goal term. </p>
</blockquote>
<p>What are the guarantees / restrictions of the proof checker vs the API? Also it was my understanding from the thread that the new proof checker relied on the same API?</p>

<a name="187607645"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187607645" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187607645">Markus Rabe (Feb 07 2020 at 02:16)</a>:</h4>
<p>Thanks for bringing this to our attention. Yes, premises with hypotheses are not fully supported in the tactic API. However, I thought that this always results in some sort of error, which it apparently does not. This looks like a serious enough issue to warrant an update of our open source version.</p>
<p><strong>The proof checker does not rely on this API</strong>, because we don't want to have to trust any of it. It was designed to catch problems like this one. The proof checker compiles the proof log into OCaml code and runs with the same guarantees that HOL Light does (modulo a couple of lines of book-keeping code written in OCaml). However, we still want the stateless API to be reliable.</p>

<a name="187612581"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187612581" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187612581">Jason Rute (Feb 07 2020 at 04:24)</a>:</h4>
<p>Here is my two cents for what it is worth:</p>
<p>That bug seems troubling and should probably be investigated and fixed.  It is possible that there are other weird side effects out there.  (However, I agree since those theorems with the assumptions are not used in practice (and shouldn't be used) that this probably doesn't present a problem.)</p>
<p>I also think that the "safety net" provided by the external proof checker seems reasonable.  (I don't know what "bookkeeping" means, but I assume a reasonable amount of care was put into this.  One can always go down a rabbit hole with stuff like this.)</p>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span>:</p>
<blockquote>
<p>This is a surprising restriction, especially since the human proof logs don't comply to it.</p>
</blockquote>
<p>I think it is a reasonable requirement to not use theorems which have assumptions as premises.  I don't recall any human-written proofs in HOL-Light (except maybe at the lowest level, just after the kernel) which use such theorems.  Moreover, they would never be necessary.  If it is not clear, I believe all of these "refl" theorems are (1) computer generated and (2) used to prove trivial propositional theorems.  Not only is <code>c = T |- c = T</code> trivial, it is used to prove trivial propositional tautologies like <code>(c ==&gt; a ==&gt; b) ==&gt; a /\ ~b ==&gt; ~c</code>.</p>
<p>From a prior investigation I did, it seems that they are automatic intermediate steps in the <code>TAUT</code> tool.  Because they are automatic, they aren't exactly human training data, and moreover, they are used to prove propositional tautologies that MESON could handle instantly.</p>
<p>Just like we don't include all the intermediate theorems in the MESON tactic, it seems reasonable not to include the intermediate theorems in TAUT, even though it is not a tactic.</p>
<p>Now, what is tricker is whether to include <code>(c ==&gt; a ==&gt; b) ==&gt; a /\ ~b ==&gt; ~c</code> as a premise, when it is used in cases like <code>MATCH_MP_TAC(TAUT `(c ==&gt; a ==&gt; b) ==&gt; a /\ ~b ==&gt; ~c`)</code>.  I think "no", but that is debatable.  In Lean and Coq, such quick lemmas would be created through the <code>have</code> tactic, and again in Lean and Coq, I don't think <code>have</code> lemmas should be premises, but that is a matter of style.</p>
<p>The best of course would be to have the AI find the <code>have</code> or <code>TAUT</code> lemmas, and that would be an amazing step forward!</p>

<a name="187621028"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187621028" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187621028">Stanislas Polu (Feb 07 2020 at 08:16)</a>:</h4>
<blockquote>
<p>Thanks for bringing this to our attention. Yes, premises with hypotheses are not fully supported in the tactic API. However, I thought that this always results in some sort of error, which it apparently does not. This looks like a serious enough issue to warrant an update of our open source version.</p>
</blockquote>
<p>Thanks <span class="user-mention" data-user-id="217806">@Markus Rabe</span>, looking forward to working with the updated version.</p>
<p>Maybe related to this issue, the human proof logs contain proof steps that appear as similarly bogus at first sight. As an example if you look at 1239658577412467327 from the validation set, it starts by a <code>DISJ_CASES_TAC</code>, no problem there, but then applies your internal <code>RAW_POP_TAC 0</code> on the two subgoals, which seems to strip the assumptions from the subgoals. The SUBST1_TAC are then applied to goals that don't have any hypothesis and should fail in native hol light.</p>
<p>Could you describe in more detail the interplay between RAW_POP_TAC and SUBST1_TAC in the human prooflogs? Also and that's what I wanted to bing here, if you fix <code>SUBST1_TAC</code> the human proof logs as they are today may become invalid?</p>

<a name="187693080"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187693080" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187693080">Sarah Loos (Feb 08 2020 at 00:26)</a>:</h4>
<p>Thanks <span class="user-mention" data-user-id="249373">@Stanislas Polu</span> for looking into the details of HOList!  I'm enjoying the conversation - hopefully this is helpful for you.</p>
<blockquote>
<p>Maybe related to this issue, the human proof logs contain proof steps that appear as similarly bogus at first sight. </p>
</blockquote>
<p>I want to come back again to the role of the human proof logs in HOList.  These are distilled automatically from human HOL Light proofs for the purpose of imitation learning on human proofs.  Converting HOL Light proofs (implemented programmatically as a single, compound tactic) to interactive proving steps is hard (see [<a href="https://link.springer.com/chapter/10.1007/978-3-662-49224-6_6" target="_blank" title="https://link.springer.com/chapter/10.1007/978-3-662-49224-6_6">Adams</a>] and discussions in this forum about recording Lean proofs) and is not a research goal of HOList.</p>
<p>Moreover, to support arbitrary exploration of the interactive proof search tree, we use a stateless prover.  Some features of HOL Light are fundamentally incompatible with a stateless approach (e.g. metavariables), but luckily are only used in a small minority of human proofs.  Other things, like forward derived theorems, are tricky to log: in this case we log the theorem values without any proof.</p>
<p>I added RAW_POP_TAC specifically to log POP_ASSUM.  If I recall correctly, the original tactic removes a specified assumption from the goal state, but keeps it in the local HOL Light environment; it then applies the next tactic using the former assumption as an argument.  How do we log the same two steps in a stateless prover?  I decided to keep the goal state the same as in the original proof (with the assumption stripped), and log the value of the theorem argument.  Just like with forward-derived theorems, these popped assumption theorems are logged without any proof or tracing of their source.</p>
<p>While many of the ~20,000 human proofs are not replayable or checkable, they are still a good resource for training, so we don't throw them out just because proof logging was incomplete.  When using deep networks to search for new proofs, the HOList API may not have access to the exact same theorem arguments that were used in the human proofs for the reasons listed above.  However, if the network learns to recognize what makes a theorem useful semantically, then it should still effectively rank the set of theorems that are available.</p>
<p>Some of our more recent results indicate that imitation learning is useful, but not critical (<a href="https://arxiv.org/pdf/1905.10501.pdf" target="_blank" title="https://arxiv.org/pdf/1905.10501.pdf">Learning to Reason in Large Theories without
Imitation</a>, <a href="https://arxiv.org/abs/1909.11851" target="_blank" title="https://arxiv.org/abs/1909.11851">Mathematical Reasoning in Latent Space</a>).  This suggests that we could greatly simplify the integration of DeepHOL/HOList with new proof assistants like Lean, since we can skip the overhead of converting human proofs in an existing library into a universal proof log format for training.  Instead, we can go straight to reinforcement learning from zero human training data.</p>

<a name="187769611"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187769611" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187769611">Stanislas Polu (Feb 09 2020 at 19:20)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> thanks for the additional context. Really enjoying the conversation as well!</p>
<p>I do appreciate your points, and I agree the human proofs serve as good training signal. But I also think that it would be very desirable if they could be as replayable as possible. I agree that this is not an easy problem.</p>
<p>On the RL argument, if we look at the big picture, even the RL approach you mention relies on some form of supervision:  the statements and how they shape the space being searched. So we know that as of today we still need some supervision to make progress in the domain. How much supervision I think is still an open question and I think Holist should try to be the right system even for approaches that rely on direct human supervision for proof steps, or at least aim at being as good of a system for that use case as possible?</p>

<a name="187769627"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187769627" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187769627">Stanislas Polu (Feb 09 2020 at 19:20)</a>:</h4>
<p>(Thank you so much for all your help!)</p>

<a name="187808089"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187808089" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187808089">Stanislas Polu (Feb 10 2020 at 11:43)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> concerning RAW_POP_TAC I see the rationale for logging purposes. I will check the logs to convince myself that  that the popped assumptions are used in subsequent proof steps. An approach could be to maintain the popped assumption as valid theorem argument in subsequent steps when sampling proofs that attempt to use this tactic.</p>

<a name="187808248"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187808248" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187808248">Stanislas Polu (Feb 10 2020 at 11:46)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> On the above and the usability of Holist for as many uses cases as possible. One thing that is highly desirable is that searching for proofs using the API is valid and supported. As an example, the bug above prevents that but do you think holist will be in a position to support that use case eventually?</p>

<a name="187808401"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187808401" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187808401">Stanislas Polu (Feb 10 2020 at 11:49)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> finally, sorry for the multiple questions, can you shed the same kind of lights on the use of RAW_POP_ALL_TAC ?</p>

<a name="187938943"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187938943" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187938943">Sarah Loos (Feb 11 2020 at 18:25)</a>:</h4>
<blockquote>
<p>On the RL argument, if we look at the big picture, even the RL approach you mention relies on some form of supervision:  the statements and how they shape the space being searched.</p>
</blockquote>
<p>Couldn't agree more with this statement!  I think this is all a matter of degree - ultimately we'd like to rely less and less on formal human proofs and formal  human-generated theorem statements, since this comprises a relatively small fraction of natural language mathematics.  Hopefully there are enough of them that they can bootstrap learning from natural language mathematics.</p>

<a name="187939406"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187939406" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187939406">Sarah Loos (Feb 11 2020 at 18:29)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239408">Sarah Loos</span> finally, sorry for the multiple questions, can you shed the same kind of lights on the use of RAW_POP_ALL_TAC ?</p>
</blockquote>
<p>See POP_ASSUM vs. POP_ASSUM_LIST in HOL Light.</p>

<a name="187940564"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/187940564" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#187940564">Sarah Loos (Feb 11 2020 at 18:40)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239408">Sarah Loos</span> concerning RAW_POP_TAC I see the rationale for logging purposes. I will check the logs to convince myself that  that the popped assumptions are used in subsequent proof steps. An approach could be to maintain the popped assumption as valid theorem argument in subsequent steps when sampling proofs that attempt to use this tactic.</p>
</blockquote>
<p>The goal state already has this - it's the assumption list!  If you look at the POP_ASSUM <a href="https://www.cl.cam.ac.uk/~jrh13/hol-light/HTML/POP_ASSUM.html" target="_blank" title="https://www.cl.cam.ac.uk/~jrh13/hol-light/HTML/POP_ASSUM.html">man page</a>, you'll see that it's really more of a convenience function than absolutely necessary.  It's essentially using an assumption combined with weakening the goal.  If you use a tactic that doesn't include all the assumptions from the assumption list (i.e. don't use ASM_* tactics), then the two should be equivalent steps.  RAW_POP_TAC is still an available tactic, but now it's just the weakening step.</p>

<a name="188012015"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188012015" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188012015">Stanislas Polu (Feb 12 2020 at 14:03)</a>:</h4>
<blockquote>
<p>The goal state already has this - it's the assumption list! If you look at the POP_ASSUM man page, you'll see that it's really more of a convenience function than absolutely necessary. It's essentially using an assumption combined with weakening the goal. If you use a tactic that doesn't include all the assumptions from the assumption list (i.e. don't use ASM_* tactics), then the two should be equivalent steps. RAW_POP_TAC is still an available tactic, but now it's just the weakening step.</p>
</blockquote>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> right, but I still don't quite see how it will impact the proof logs once you fix SUBST1_TAC. As current proof logs won't be valid anymore?</p>
<p>I think, the most important thing should be that a proof search relying on the API should be guaranteed to be consistent if goals/subgoals are properly handled when talking to the API. And the second thing that I campaign for is for the human proof logs to be as replayable as possible (coqgym's proof logging system seems to achieve that goal as an example)</p>

<a name="188020642"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188020642" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188020642">Stanislas Polu (Feb 12 2020 at 15:35)</a>:</h4>
<p><span class="user-mention" data-user-id="239408">@Sarah Loos</span> <span class="user-mention" data-user-id="217806">@Markus Rabe</span> <code>4244727170697809164</code> is also interesting as the last ACCEPT_TAC is, I believe, inconsistent as well (preceded with a RAW_POP_TAC that removes the required hypothesis)</p>

<a name="188064869"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188064869" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188064869">Sarah Loos (Feb 12 2020 at 23:45)</a>:</h4>
<blockquote>
<p>I think, the most important thing should be that a proof search relying on the API should be guaranteed to be consistent if goals/subgoals are properly handled when talking to the API.</p>
</blockquote>
<p>I definitely agree here - we want anything that interacts with the API to be reliable.  This is moving a lot of soundness-critical code to be managed faster and more flexibly by the external proof search, so on top of this I would still add a proof checker that ensures correctness of the synthetic proofs purely via the proof assistant.  For example, we can always register a theorem "False" and then prove anything, but the proof checker should reject these proofs.</p>

<a name="188065156"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188065156" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188065156">Sarah Loos (Feb 12 2020 at 23:49)</a>:</h4>
<p>One of the biggest open research questions for automated reasoning about mathematics is figuring out the right level of abstraction.  How do we represent a theorem?  How do we represent a proof step?  This is one of the fundamental differences between reasoning about mathematics and strategizing about steps in a game of Go, where the definition of an action is clearly defined and fixed.</p>
<p>The "best" representation will depend on what's most appropriate for the specific algorithm or human that is driving the search.  For proof search guided by deep networks, I think this question is largely unanswered and unexplored, but hopefully won't be that way for long!</p>
<p>Our approach with HOList is to mimic a human working with HOL Light in interactive mode.  Additionally, rather than asking a network to distinguish the hundreds of <a href="https://www.cl.cam.ac.uk/~jrh13/hol-light/reference.html" target="_blank" title="https://www.cl.cam.ac.uk/~jrh13/hol-light/reference.html">tactics and rules</a> implemented in HOL Light, we limit it to 41 basic tactics.  These tactics were not chosen arbitrarily, but rather through adding logging systematically by updating the justification type.  To leverage the programmatic human proofs in the HOL Light library as training data for interactive proving, we automatically map them into prooflogs that match our action space of 41 tactics, with some steps (e.g. forward proof derivations) omitted.</p>
<p>CoqGym is using a higher-level abstraction of a proof step: each step can be an arbitrarily complex (and for human proofs, compound) programmatic tactic, defined by a two-page context-free grammar (ASTactic).  Most of the existing coq proofs already fit this paradigm, so logging the human proofs does not require significant rewriting.  It's worth noting that they also had to throw out some human proofs that use goal selectors and that the action space of ASTactics that can be generated by the trained models is not the full space available in the human proofs. </p>
<p>Interactive theorem provers typically implement more proving features than can reasonably be learned by current deep learning approaches.  So what should we do with human proofs that use these additional features?  In the release of our human proof logs, we attempt to convert and unroll as many steps as possible from the programmatic tactic language to the 41 interactive tactics in our action space.  Other reasonable approaches are to train on them as-is or to omit them altogether.</p>

<a name="188067518"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188067518" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188067518">Jason Rute (Feb 13 2020 at 00:22)</a>:</h4>
<p>I might just add that it seems to me that logging Lean proofs will be quite the task too if we ever decide to do it.  There is a lot of flexibility in Lean proofs; the tactic language is a full programming language and is readily extendible; the community has been quite productive in making custom tactics; one has to deal with tactic parameters which get interpreted according to the context; the behavior of some tactics change as other theorems are proved (for example I believe theorems can be added to the <code>simp</code> tactic); and one can at any point in a proof switch from tactic mode to term mode (forward proving).  (Also implicit parameters, type classes, and private theorems add their own complexities.)  All these things make Lean great as a programming language and theorem prover, but will make tactic logging difficult.</p>

<a name="188083341"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188083341" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188083341">Christian Szegedy (Feb 13 2020 at 07:08)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="239408">Sarah Loos</span> <span class="user-mention silent" data-user-id="217806">Markus Rabe</span> <code>4244727170697809164</code> is also interesting as the last ACCEPT_TAC is, I believe, inconsistent as well (preceded with a RAW_POP_TAC that removes the required hypothesis)</p>
</blockquote>
<p>BTW, we are about to release an update to the HOL-Light RPC API, hopefully by end of this week, including:</p>
<ul>
<li>Verifying that theorem parameters do not have hypotheses. (This is a bit restrictive, but it seems that they just cause trouble for now. Hypotheses can be replaced by implications, so we can live with that for now.)</li>
<li>Some experimental forward reasoning support. It is not supported by the proof checker, but feel free to play with it.</li>
<li>Fixed fingerprinting. (Correct fingerprint returned).</li>
<li>Better support of goal assumptions.</li>
</ul>
<p>We are in the process of verifying that the new API is compatible with the open-sourced DeepHOL code base. We might need to cherry-pick some of the changes if they conflict with the DeepHOL code we have not updated in the open-source version.</p>

<a name="188083567"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188083567" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188083567">Christian Szegedy (Feb 13 2020 at 07:15)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> </p>
<blockquote>
<p>I might just add that it seems to me that logging Lean proofs will be quite the task too if we ever decide to do it.  </p>
</blockquote>
<p>In the longer term, we are working on a more generic variant of DeepHOL that does not rely on an engineered, internal view of the goal stack.  Basically, the AI  would just interact by normal character sequences, similar to those a human user would produce. Also it could use extra side-information from stored human proofs or interactive interaction instead of structured proof-logs. This would allow us to simplify the system while relying more heavily of current state-of-the-art AI/Deep-Learning methods.</p>
<p>Also this could mean that it will interface easier with Lean and could utilize sloppier training signals in a more flexible manner.</p>

<a name="188264219"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188264219" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188264219">Christian Szegedy (Feb 15 2020 at 01:54)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span>, today we have released our first update to the Holist HOL Light backend on GitHub and the  <a href="http://gcr.io/deepmath/hol-light" target="_blank" title="http://gcr.io/deepmath/hol-light">gcr.io/deepmath/hol-light</a> docker image.</p>
<p>Changes include:</p>
<ul>
<li>Safer theorem registration (hypotheses are disallowed)</li>
<li>More consistent fingerprint support (correct fingerprint is returned during registration)</li>
<li>Fingerprinting fixed for goals with assumptions.</li>
<li>Some limited support for forward reasoning rules.</li>
</ul>
<p>Feedback, discussions and external contributions are welcome.</p>

<a name="188277216"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188277216" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188277216">Stanislas Polu (Feb 15 2020 at 09:49)</a>:</h4>
<p><span class="user-mention" data-user-id="239426">@Christian Szegedy</span> great news! I will experiment with it next week <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span> A few quick questions:</p>
<ul>
<li>the proof logs haven't been updated right? Which means the safer theorem registration breaks most proof replays. I know your position is that it is not a problem but just wanted to get the final state we're in right now?</li>
<li>Do you have any documentation for the forward reasoning rules support?</li>
<li>Does the safer theorem registration fixes all inconsistencies in the API? If so can you explain how it fixes it?</li>
</ul>
<p>Thanks!</p>

<a name="188297032"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188297032" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188297032">Christian Szegedy (Feb 15 2020 at 20:17)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> </p>
<ul>
<li>Prrof logs have not been not updated. Fingerprinting changes affect only theorems with hypotheses, that we disallow in our proofs (not in human proofs though). AFAICR, the proof-logs contain the theorem text for all intermediate  theorems, so their fingerprints could recomputed on the python side easily if necessary. BTW, since the python side fingerprinting did not change, I think that old proof-logs could still be completely valid. We can verify that.</li>
<li>We have no extra documentation for rules. You have an extra RPC call: ApplyRule and the request should be of the form:<br>
&lt;RULE&gt; &lt;PRM1&gt; &lt;PRM2&gt; ...<br>
where PRMi can be either a parameter or a list of parameters enclosed in braces (space around braces is mandatory). The theorems are given as THM  &lt;FINGERPRINT&gt;<br>
For the possible rules, it is best referred to:<br>
<a href="https://github.com/brain-research/hol-light/blob/35956b7edf34b1ba3fb5c54f4eb108ab08eada03/parse_tactic.ml#L165" target="_blank" title="https://github.com/brain-research/hol-light/blob/35956b7edf34b1ba3fb5c54f4eb108ab08eada03/parse_tactic.ml#L165">https://github.com/brain-research/hol-light/blob/35956b7edf34b1ba3fb5c54f4eb108ab08eada03/parse_tactic.ml#L165</a><br>
fore example:<br>
rule: "CONJUNCT1 THM 3889194075140062007"<br>
or:<br>
rule: "ASM_REWRITE_RULE [ ] THM 4453115153695028333"</li>
</ul>

<a name="188318573"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188318573" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188318573">Stanislas Polu (Feb 16 2020 at 08:55)</a>:</h4>
<p>Thanks <span class="user-mention" data-user-id="239426">@Christian Szegedy</span>.</p>
<p>I personally feel (but might be wrong) that these changes make Holist quite specialized towards RL approaches. As I'm still actively investigating "more" supervised approaches, I wanted to share as feedback for the Holist project that I may prioritize other systems (because a large fraction of valid predicted proof steps have become invalid through the API at this stage, when trained from the human proof logs).</p>
<p>Also, what about the third question?</p>
<p>Thanks again for your help and all the productive exchanges with you and the rest of the team (and looking forward to continuing those!)</p>

<a name="188319714"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188319714" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188319714">Christian Szegedy (Feb 16 2020 at 09:41)</a>:</h4>
<p><span class="user-mention silent" data-user-id="249373">Stanislas Polu</span></p>
<blockquote>
<p>I personally feel (but might be wrong) that these changes make Holist quite specialized towards RL approaches.</p>
</blockquote>
<p>Our first focus is soundness. We've known for a long time that using theorems with hypotheses yielded unsound results, that's why we have filtered them out from our theorem database. The recent changes just make those earlier decisions more explicit. We have a definitive proof verifier at the end, but we don't want to rely on that during normal use.</p>
<p>The new changes just represent a safe-guard that seems necessary at this point in time. We will remove parts of those safe-guards as we start to allow more forward reasoning capabilities. For now, we err on the conservative side.</p>
<p>I can see several alternatives forward:</p>
<ul>
<li>We make sure that all backward tactic applications are completely sound in the presence of theorem parameter hypotheses. (This would require a lot of extra work and validations, as we don't exactly know all the possible causes of unsoundnesses in each tactic.)</li>
<li>Allow forward rules to create and register theorems with hypotheses, but we would disallow them for being used in all backward rules.</li>
<li>Every time we try to register a theorem with hypotheses, we would turn it into an implication without hypotheses.</li>
<li>At every tactic application step we would create a definitive forward proof that the produced goals would imply the input goal.</li>
</ul>
<p>However, I think that Instead of allowing theorems with hypotheses, it is much higher priority to make forward rules being utilized and supported fully, since that what makes hypotheses compelling in the first place.</p>

<a name="188320108"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/188320108" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#188320108">Christian Szegedy (Feb 16 2020 at 09:57)</a>:</h4>
<p><span class="user-mention silent" data-user-id="249373">Stanislas Polu</span></p>
<blockquote>
<ul>
<li>Does the safer theorem registration fixes all inconsistencies in the API? If so can you explain how it fixes it?<br>
Thanks!</li>
</ul>
</blockquote>
<p>The problem is that some of the tactics can be unsound in the presence of hypotheses. For example, in the case of SUBST the unsoundness is removed by extra checks outside the tactic. In our first RL experiments, the system managed to figure out and utilize those unsound operations, so we removed theorems with hypotheses from our theorem database. Since then, none of our RL loops (which used many thousand CPU years, so far) could not create any unsound proofs (as we verify them with our forward proof-checker that goes through the kernel.) This is a very strong indication that our current backward-reasoning system is sound too with the current setup.</p>
<p>Checking the soundness of isolated backward reasoning steps is much harder than complete forward proof traces, since individual backward reasoning steps can't be checked easily in the current setup, so we can fully trust only the final proofs if we verify them with the proof-checker, however we do that step rarely as it adds extra complexity.</p>
<p>The correctness of forward rules can be trusted more, since all the steps are immediately verified with the kernel.</p>
<p>Therefore I think that the highest priority is to support forward proofs more (in the verifier and DeepHOL) and once we can use them, we can allow theorems with hypotheses to be parameters of selected tactics then.</p>

<a name="190524330"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190524330" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190524330">Grant G (Mar 13 2020 at 16:29)</a>:</h4>
<p>I am trying to experiment with changing the NN in the Deephol prover system.  However,  the jupyter notebook example doesn't work for me, and the Dockerfile has issues. Does anyone have a fully functioning environment, where they can compile and train a new network?</p>

<a name="190526215"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190526215" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190526215">Stanislas Polu (Mar 13 2020 at 16:45)</a>:</h4>
<p>I would recommend using the Docker directly, using <span class="user-mention" data-user-id="115715">@Jason Rute</span> 's notebook as a starting point. Happy to help!</p>

<a name="190526330"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190526330" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190526330">Stanislas Polu (Mar 13 2020 at 16:46)</a>:</h4>
<p><a href="https://github.com/jasonrute/holist-communication-example" target="_blank" title="https://github.com/jasonrute/holist-communication-example">https://github.com/jasonrute/holist-communication-example</a></p>

<a name="190599487"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190599487" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190599487">Jason Rute (Mar 14 2020 at 14:30)</a>:</h4>
<p><span class="user-mention" data-user-id="248602">@Grant G</span> There are two levels of abstraction/API for HOList.  One is a python API which should let you change the neural network model being used.  It is well documented by Aaron Hadley and others in a Jupyter notebook.  (See the first message in this HOList thread for links.)  The is also another gRPC API for connecting directly to HOL Light.  That is documented in another notebook by me.  (Again see the first message for links.)  Can you be more clear about what issues you are facing including which notebook and docker files you are having trouble with and what sort of problems you are facing?  Also, I think you should be using the notebook by Aaron and others.  I think it better fits your use case.  Second, if you are using my notebook, there have been recent changes to the HOList docker. And I don’t know if my notebook still works.  Let me know if it doesn’t (or if it is inaccurate) and I’ll try to update it.</p>

<a name="190750023"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190750023" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190750023">Grant G (Mar 16 2020 at 16:52)</a>:</h4>
<p>Thanks for helping me out with the issue. I will give an outline of what is going on, and I will try to get the details later. (I have to work on my other project today). I tried to use Aaron's jupyter notebook first. When I tried to build using bazel I had a compilation error </p>
<p>external/grpc/src/core/lib/gpr/log_linux.cc:43:13: error: ambiguating new declaration of 'long int gettid()'</p>
<p>I did some googling and it seems like it is a version issue. Next I tried to build the Docker file, but that also had issues compiling due to  the docker file having non-absolute versioning.  I tried to fix that and was able to compile, but  when I called main it would throw an error  unable to import numpy. </p>
<p>So I am just trying to bypass all this debugging by getting something stable to work with TBH. </p>
<p>I also attached the Docker file that works up until the python import error.  I added the lines to reinstall the python dependence in the hope that it would fix things, and I changed the base containers. Otherwise it is the Docker file from deepmath-jupyter.<br>
<a href="/user_uploads/3121/Y-oHgTNqc0lksojKvzDejxy9/Dockerfile" target="_blank" title="Dockerfile">Dockerfile</a></p>

<a name="190758080"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190758080" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190758080">Kshitij Bansal (Mar 16 2020 at 17:50)</a>:</h4>
<p>Can you try with the bazel version 0.24.1 in the Dockerfile instead of latest?</p>
<p>That is,</p>
<p>FROM <a href="http://l.gcr.io/google/bazel:0.24.1" target="_blank" title="http://l.gcr.io/google/bazel:0.24.1">l.gcr.io/google/bazel:0.24.1</a></p>

<a name="190759968"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190759968" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190759968">Grant G (Mar 16 2020 at 18:05)</a>:</h4>
<p><a href="/user_uploads/3121/EK4c1r75rJVTHAAR9oF8kIlC/Dockerfile" target="_blank" title="Dockerfile">Dockerfile</a> <br>
Sorry I uploaded the wrong file I used. 0.21.0. I will update the version and give it another run tonight.</p>

<a name="190783389"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190783389" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190783389">Kshitij Bansal (Mar 16 2020 at 21:39)</a>:</h4>
<p>Actually I tried with 0.24.1 and still get the import numpy issue. I am not sure what has changed, since the image <a href="http://gcr.io/deepmath/deephol" target="_blank" title="http://gcr.io/deepmath/deephol">gcr.io/deepmath/deephol</a> is still working, which was built using bazel version 0.24.1 (at the time latest) and the provided Dockerfile.</p>

<a name="190791037"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/190791037" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#190791037">Kshitij Bansal (Mar 16 2020 at 23:06)</a>:</h4>
<p>So, I don't know what the issue is. But I am able to build a working one if I go back to an older commit in the deepmath repo &amp; also update the bazel version.</p>
<p>To summarize, I tested the following works:</p>
<ol>
<li>Clone the deepmath repo.</li>
<li>git checkout 882f84a</li>
<li>Change the first line of the Dockerfile to "FROM <a href="http://l.gcr.io/google/bazel:0.24.1" target="_blank" title="http://l.gcr.io/google/bazel:0.24.1">l.gcr.io/google/bazel:0.24.1</a>"</li>
<li>Built the docker image.</li>
<li>Tested using the instructions on the website (<a href="http://deephol.org" target="_blank" title="http://deephol.org">deephol.org</a>) using this docker image instead of <a href="http://gcr.io/deepmath/deephol" target="_blank" title="http://gcr.io/deepmath/deephol">gcr.io/deepmath/deephol</a></li>
</ol>

<a name="191258708"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/191258708" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#191258708">Grant G (Mar 20 2020 at 15:33)</a>:</h4>
<p>Thanks! It builds and doesn't have the same python errors.</p>

<a name="191644723"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/191644723" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#191644723">Grant G (Mar 24 2020 at 17:23)</a>:</h4>
<p>I am  having issues building the proof checking docker image  Dockerfile_check_proofs from the website. I get the following error.</p>
<p>Step 1/16 : FROM ocaml/opam:ubuntu-16.04_ocaml-4.03.0<br>
pull access denied for ocaml/opam, repository does not exist or may require 'docker login': denied: requested access to the resource is denied</p>
<p>So I replaced that FROM with FROM ocaml/opam2:ubuntu-16.04-ocaml-4.03.0, and then had a new issue. I think this issue is from around the step of building hashfarm. </p>
<p>theorem_fingerprint_c.cc:1:25: fatal error: caml/memory.h: No such file or directory<br>
compilation terminated. </p>
<p>However, it is my understanding that the HOList won't allow an agent to produce a false proof.(Ignoring the issue stated above about RegisterTheorem). So verification is unnecessary for training an agent.</p>

<a name="192425843"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192425843" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192425843">Grant G (Mar 31 2020 at 17:54)</a>:</h4>
<p>Has anyone attempted to turn the HOList system into a openai gym environment?</p>
<p>I realize that doing that in the most straight forward way would result in some serious downsides, but currently that seems like the most effective way to move my research project forward.</p>

<a name="192462558"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192462558" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192462558">Jason Rute (Mar 31 2020 at 22:43)</a>:</h4>
<p>Ignoring the technical challenges, does it even fit the format of an open ai gym environment?  Tactic selection might, but what about premise selection?  Also, can you do a tree search in an open ai gym environment?  For example can the board game go (a la alphago) be made into an open ai gym environment?  I thought those didn’t allow backtracking, but I’m not an expert.</p>

<a name="192465856"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192465856" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192465856">Jason Rute (Mar 31 2020 at 23:23)</a>:</h4>
<p><span class="user-mention" data-user-id="248602">@Grant G</span>  I don't know if I can be a huge help, but what is it that you are trying to do accomplish, big picture?  Is the idea that you want to keep the general flavor of the HOList project with its tree search, etc, but to train and use your own ML algorithm?  Were you able to follow the notebook <a href="https://github.com/aahadley/deepmath-jupyter/blob/master/HOLJup.ipynb" title="https://github.com/aahadley/deepmath-jupyter/blob/master/HOLJup.ipynb">here</a> and the tutorial <a href="https://github.com/aahadley/deepmath-jupyter/blob/master/TutorialPaper.pdf" title="https://github.com/aahadley/deepmath-jupyter/blob/master/TutorialPaper.pdf">here</a>?  The proof checker isn't 100% needed.  The problem is that the HOList environment is not a 100% accurate simulation of HOL Light, so in a small percentage of cases your agent can find a proof which won't work in HOList.  (I don't know the details to know if it is unsound or just has issues with timeouts or tactic parameters.)  The proof checker is there to give you 100% confidence that the proofs your agent found do work in HOL Light, because it translates the proofs to HOL Light and runs them.  It is certainly not needed to get started with HOList.</p>

<a name="192473242"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192473242" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192473242">Jesse Michael Han (Apr 01 2020 at 01:08)</a>:</h4>
<blockquote>
<p>Tactic selection might, but what about premise selection?</p>
</blockquote>
<p>I'm not sure how it's handled in their system, but it's indeed probably unwise to be constantly transmitting valid-action masks the size of the entire theorem database; it would seem better to let each agent own a copy of the theorem database and perform the filtering based on the fingerprints themselves.</p>
<blockquote>
<p>Also, can you do a tree search in an open ai gym environment?</p>
</blockquote>
<p>The environment decides when the episode ends; for example, GQSAT (<a href="https://arxiv.org/pdf/1909.11830.pdf" title="https://arxiv.org/pdf/1909.11830.pdf">link</a>) used a <code>gym</code>-like environment for DPLL search.</p>

<a name="192473679"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192473679" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192473679">Jesse Michael Han (Apr 01 2020 at 01:16)</a>:</h4>
<p>In the case of HOList, however, I think(?) the tree search is maintained by the agent and not the environment, which is mainly responsible for applying tactics and returning lists of goals.</p>

<a name="192476720"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192476720" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192476720">Jason Rute (Apr 01 2020 at 02:12)</a>:</h4>
<p>So I guess it would be possible.  The environment would hold the search tree (or at least a list of all visited states).  The <code>step</code> method would be to expand a node in the search tree, namely one would pass the following:</p>
<ol>
<li>The id of the node to apply an action to.  (A node would be a goal state where you are trying to solve the first goal in the state.)</li>
<li>The tactic to apply.</li>
<li>A list of premises (given by fingerprints) to use as tactic arguments for the tactic.</li>
</ol>
<p>The response would describe the new goal state, including its id.  If it ever reaches a solved state then one "wins".  (Note, selection of the node id would probably be handled by some standard search algorithm like beam search or MTCS instead of, say, a pointer neural network.)</p>
<p>One danger of this approach is that the environment would have to keep track of the entire search tree, and would never know when to prune a branch.  I don't know if this is a large deal or not.  Another danger is that the tree search couldn't be easily parallelized.</p>
<p>One more question, besides how to implement the above, would be if one can specify a certain starting position in an environment.  This would be important for some of the proof exploration that the HOList RL papers use.</p>

<a name="192476853"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192476853" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192476853">Grant G (Apr 01 2020 at 02:15)</a>:</h4>
<p><span class="user-mention" data-user-id="116045">@Jesse Michael Han</span> Thanks for the link to the Sat paper that should help with the implementation .</p>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> The goal is to make it agent easier to modify. I would like to try out some of the newer ML algorithms that deal better with long term credit assignment , and I would like to try out a Neural Architecture Search, and I would like to try out new reward structures. </p>
<p>For my other work I use rllib to make hyperparameter searching easier, and so I don't have to reimplement  various RL baseline algorithms. My lab has some very beefy super computers so NAS maybe doable. Gym environments are easy to use with rllib.</p>
<p>As for the gym details. It shouldn't be too hard to have the graph search be part of a hidden state that the environment keeps track off. The thm database is an issue. If thinks were stateless then, it would just be a integer set mapping to the thm finger prints, but I really don't know how to deal with that at the moment. The second issue is how to encode the goal/subgoal state space . I don't know how to do something reasonable yet text input to a gym environment where the text can be so long, and have it work well with gym+rllib</p>
<p>So I am going remove various functionality until I can come up with a better way of doing things. Try something with a fixed number of theorems loaded, and allow deeper proofs to try to compensate, and pick a large enough text embedding space, and just junk anything too long, instead of trying to learn a principled goal embedding in a NN fashion.</p>

<a name="192476949"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192476949" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192476949">Jason Rute (Apr 01 2020 at 02:17)</a>:</h4>
<p>Jessie, as for what the "environment" in HOList is, there are two APIs for HOList.  The low level one is indeed responsible for just applying tactics and returning goals.  The higher level one is a python API which is also responsible for handling the beam search if I am not mistaken.  In that one, I think the user would only have to specify the NN functions which rank and predict tactics and premises (if I am remembering correctly).  This would be something in-between.</p>

<a name="192477287"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192477287" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192477287">Grant G (Apr 01 2020 at 02:24)</a>:</h4>
<p>Much of the code for training an agent has been removed, or doesn't run in the current released code for deephol(According to the notes in the readme files in the repo). If I made a gym environment it would wrap some of the utility code from deephol, and the holist environment and try to simplify everything further down to  something really trivial for most people to use.</p>
<p>Anyways, sorry about your wedding getting delayed. Thanks for the help.</p>

<a name="192477372"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192477372" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192477372">Jason Rute (Apr 01 2020 at 02:27)</a>:</h4>
<p><span class="user-mention" data-user-id="248602">@Grant G</span> Theoretically you could build that as a wrapper around the protobuf API for the HOList docker image. You wouldn't have to deal at all with DeepHOL nor look inside the HOList docker.  I've documented the protobuf API <a href="https://github.com/jasonrute/holist-communication-example" title="https://github.com/jasonrute/holist-communication-example">here</a> although it might be slightly out of date.  Note that DeepHOL doesn't currently use the whole protobuf API.  They don't supply term arguments for example, so they can't use EXISTS_TAC for example.  Also, make sure your agent isn't allowed to use CHEAT_TAC. :)  If you are doing entirely supervised learning, (or at least not exploring new theorems or using new premises) then it should be possible to just have a fixed index for all the possible premises.  I might be overlooking something here.</p>

<a name="192477806"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192477806" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192477806">Jason Rute (Apr 01 2020 at 02:38)</a>:</h4>
<p>Although, if you are going to use pre-built RL algorithms, do any of them do model-based RL where they can explore a tree of possible states using a model of the world (like solving a Rubik's cube)?  I ask because you probably are not interested in having tree-search be part of the whole problem right?  (I.e. you are not asking your agent to rediscover a tree/graph search algorithm, right?)</p>

<a name="192478004"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192478004" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192478004">Jason Rute (Apr 01 2020 at 02:44)</a>:</h4>
<p>Also, for the record, if one could unify a number of ITP and ATP setting into a single API, even if that API is not the open ai gym one, then I would be all for it.  I think the barrier to entry is incredibly high to start work on problems like this and that is really unfortunate.</p>

<a name="192526478"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192526478" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192526478">Jason Rute (Apr 01 2020 at 13:25)</a>:</h4>
<p>I looked into rllab.  Note that the HOList and similar RL algorithms would fall most closely under the category of <a href="https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html" title="https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html">model-based RL with a given model</a> of which <a href="https://spinningup.openai.com/en/latest/spinningup/keypapers.html#b-model-is-given" title="https://spinningup.openai.com/en/latest/spinningup/keypapers.html#b-model-is-given">alphago and its variants</a> are the best known examples.  It seems that rllab has at least model of that category, namely <a href="https://ray.readthedocs.io/en/latest/rllib-algorithms.html#single-player-alpha-zero-contrib-alphazero" title="https://ray.readthedocs.io/en/latest/rllib-algorithms.html#single-player-alpha-zero-contrib-alphazero">single-player alpha zero</a>.  Looking at <a href="https://github.com/ray-project/ray/tree/master/rllib/contrib/alpha_zero" title="https://github.com/ray-project/ray/tree/master/rllib/contrib/alpha_zero">the docs for it</a>, the docs specify that the environment needs to have <code>get_state</code> and <code>set_state</code> methods.  If one can implement those (see <a href="https://github.com/ray-project/ray/blob/master/rllib/contrib/alpha_zero/environments/cartpole.py" title="https://github.com/ray-project/ray/blob/master/rllib/contrib/alpha_zero/environments/cartpole.py">their cart pole example</a>), then yes, one can used model-based RL algorithms with a given model.  However, at least for this particular alpha zero algorithm, it requires some other things that I don't think are agreeable to HOList (or interactive theorem proving in general).  For example:</p>
<ul>
<li>each observation is "either the form of a state vector or an image".  Neither really fits.  The observations in HOList are formulas or lists of formulas.  Observations are more naturally expressed as strings, trees, or graphs.  One would have to use pre-learned formula embeddings taken from HOList (or hand-crafted embeddings).</li>
<li>the environment "has a discrete action space".  As per the discussion above, I just don't know if it makes sense to consider the premises as being part of a fixed size action space.  One would need something like O(T * (P choose N)) actions where T is the number of tactics, P is the number of possible premises, and N is the longest list of premises allowed in a tactic argument.  Even if that is not an issue, premises should not be thought of as categorical.  They have information in them and when this algorithm is applied to a new mathematical domain the premises will change (or at least grow).  They are not fixed axioms.</li>
</ul>

<a name="192527486"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192527486" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192527486">Jason Rute (Apr 01 2020 at 13:32)</a>:</h4>
<p>Of course one could implement HOList as a model-free environment instead, but in my opinion, the would be miss out on a lot of what makes ITP unique.  Namely that the environment can be perfectly simulated (and that there is nothing wrong with backtracking).  Of course there is also the middle ground approach of model-based RL with a learned model.  The recent <a href="https://arxiv.org/abs/1911.08265" title="https://arxiv.org/abs/1911.08265">muzero work</a> is a great example of this where they learned a model for go (and Atari) instead of using an exact given model.  It would be interesting to apply muzero to HOList or something similar, and <a href="https://arxiv.org/abs/1909.11851" title="https://arxiv.org/abs/1909.11851">this paper by Google</a> seems to hint at that possibility.</p>

<a name="192604511"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192604511" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192604511">Jason Rute (Apr 01 2020 at 23:19)</a>:</h4>
<p><span class="user-mention" data-user-id="248602">@Grant G</span> I don't know if it is important for you to compete with the HOList benchmarks or you just want a gym-like environment to try out theorem proving, but if it is the latter, you might want to check out the environment mentioned <a href="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/192603711" title="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/192603711">here</a> and see their <a href="http://aitp-conference.org/2020/abstract/paper_7.pdf" title="http://aitp-conference.org/2020/abstract/paper_7.pdf">abstract for AITP 2020</a>.  They seemed to have built a Gym environment for HOL4 (which is similar to HOL-Light).  I don't think it is public yet, but you can ask <span class="user-mention" data-user-id="110187">@Minchao Wu</span> about it since he is the main author and frequents Zulip.</p>

<a name="192607712"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/HOList/near/192607712" class="zl"><img src="https://leanprover-community.github.io/assets/img/zulip2.png" alt="view this post on Zulip"></a> <a href="https://leanprover-community.github.io/archive/219941MachineLearningforTheoremProving/34292HOList.html#192607712">Grant G (Apr 02 2020 at 00:06)</a>:</h4>
<p>Thanks. I just sent a message, but I think the benchmarks are going to be the important part in the long run.</p>


{% endraw %}

{% include archive_update.html %}